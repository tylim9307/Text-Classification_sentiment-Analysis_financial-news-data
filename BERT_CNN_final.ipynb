{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_CNN_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3375b025084944588359fa572d1132b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6879cbeaf7ad4a61ba6341319485b6b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4159ff445297463ca6508806862c7413",
              "IPY_MODEL_c0a40a0911934e638f21077587cfa329"
            ]
          }
        },
        "6879cbeaf7ad4a61ba6341319485b6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4159ff445297463ca6508806862c7413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_37994fc0a3444d45b80bba87bf65a926",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96dce8b123584d98ab588864d8604307"
          }
        },
        "c0a40a0911934e638f21077587cfa329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2369a730acab4d43ae06184b7085a626",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 905kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4faacd6a74f84ae7901a0e8ce201a476"
          }
        },
        "37994fc0a3444d45b80bba87bf65a926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96dce8b123584d98ab588864d8604307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2369a730acab4d43ae06184b7085a626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4faacd6a74f84ae7901a0e8ce201a476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bab3658a665b4c4881c7425872507e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d2221167ac6948bfb16710269381a0f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_297651a41f1e4ceaae7937f5678e5577",
              "IPY_MODEL_6dd2d01b3e834121bdb207f7a3b89da5"
            ]
          }
        },
        "d2221167ac6948bfb16710269381a0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "297651a41f1e4ceaae7937f5678e5577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90348a81cc0644bbacc58881547384d7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_317e49802f2849a1813dc7fa7e177c26"
          }
        },
        "6dd2d01b3e834121bdb207f7a3b89da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c555dbd8f8404c7e9df9f54f8214536b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.54kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab7533ff2c28470a8270f1f859f03f6b"
          }
        },
        "90348a81cc0644bbacc58881547384d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "317e49802f2849a1813dc7fa7e177c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c555dbd8f8404c7e9df9f54f8214536b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab7533ff2c28470a8270f1f859f03f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4a846fe557342d7b3f6722e0369802f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_073a29d4b7dd479885495858b199960d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c0fcc534bee043759a2cf9abba84485d",
              "IPY_MODEL_8a57dbf12c0b438497c7b983e9055e83"
            ]
          }
        },
        "073a29d4b7dd479885495858b199960d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0fcc534bee043759a2cf9abba84485d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a4a50981d8345638c91c423a342ee61",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8831987828a54a11950099a8e36850ab"
          }
        },
        "8a57dbf12c0b438497c7b983e9055e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2f58b32552140658b51c56e7c1575fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:35&lt;00:00, 12.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f84be6879a642b7b3b3173309e1becf"
          }
        },
        "4a4a50981d8345638c91c423a342ee61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8831987828a54a11950099a8e36850ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2f58b32552140658b51c56e7c1575fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f84be6879a642b7b3b3173309e1becf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tylim9307/Text-Classification_sentiment-Analysis_financial-news-data/blob/master/BERT_CNN_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66bwBypAojd0",
        "colab_type": "text"
      },
      "source": [
        "# About the notebook\n",
        "\n",
        "The following notebook contains the Bert model with Convolutional Neural Network for the classification purpose (sentiment analysis & text classification). The notebook has a following order:\n",
        "\n",
        "1. [Data Import & Preprocess](#section_1)\n",
        "2. [Tokenization & Preprocess for model](#section_2)\n",
        "3. [Fine-Tuning Function](#section_3)\n",
        "4. [Fine-Tuning](#section_4)\n",
        "5. [Confusion matrix & Critical Error](#section_5)\n",
        "6. [Train & Test](#section_6)\n",
        "\n",
        "Please refer to the BERT_Linear_layer for the purpose of the note book.\n",
        "The original idea is from [source_code](https://github.com/yoonkim/CNN_sentence) and [article](https://arxiv.org/abs/1408.5882). Please follow the link for those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i7BYV36b5WO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "71bc667b-d241-447f-da08-36dbab74799e"
      },
      "source": [
        "#===============================================================================\n",
        "# Import Libraries and Download module necessary for the deep learning\n",
        "#===============================================================================\n",
        "\n",
        "#huggingface library installation\n",
        "!pip install transformers\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from transformers import BertForTokenClassification, AdamW, BertConfig, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import transformers\n",
        "from torch.utils.data import TensorDataset, random_split,DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import datetime\n",
        "from platform import python_version\n",
        "import sklearn\n",
        "import torch\n",
        "\n",
        "#Using Colab GPU for training\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "#To confirm that we are using GPU for the training later\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b11cd6a07fd9b2506621bd2b45dd038aac313f48cddf080ce4043f34345c9a95\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZc-QlKTb_DN",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data Import & Preprocess <a class=\"anchor\" id=\"section_1\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdSCp7A4b9t9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "c8d88f5a-e31c-45e3-a02b-d7d2d2179ecb"
      },
      "source": [
        "#===============================================================================\n",
        "# Load Google Drive for the data\n",
        "#===============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_direction = '/content/drive/My Drive/KIS data/CIMS_news_with_bertext_sum_full.xlsx'\n",
        "df = pd.read_excel(file_direction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yFC-sRicAP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5748db3c-8568-46c8-fad3-18a024caccac"
      },
      "source": [
        "#===============================================================================\n",
        "# Text Data & label preprocess for the model\n",
        "#===============================================================================\n",
        "\n",
        "print(len(df))\n",
        "idx_to_remove = []\n",
        "for i in range(len(df)):\n",
        "  if type(df['summary_v2'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "\n",
        "df = df.iloc[list(set(df.index) - set(idx_to_remove))]\n",
        "df.index = np.arange(0, len(df))\n",
        "print(len(df))\n",
        "\n",
        "df['importance'] = df['score']\n",
        "\n",
        "#score by daumsoft:\n",
        "#sentiment: 3 - positive, 2 - neutral, 1 - negative\n",
        "#score: 3 - important, 2 - normal, 1 - negligible \n",
        "for i in range(len(df)):\n",
        "  if df.loc[i,'sentiment'] == 3:\n",
        "    df.loc[i,'sentiment'] = 2\n",
        "  elif df.loc[i,'sentiment'] == 2:\n",
        "    df.loc[i,'sentiment'] = 1\n",
        "  elif df.loc[i,'sentiment'] == 1:\n",
        "    df.loc[i,'sentiment'] = 0\n",
        "  if df.loc[i, 'score'] == 1:\n",
        "    df.loc[i, 'importance'] = 0\n",
        "  elif df.loc[i, 'importance'] == 2:\n",
        "    df.loc[i, 'importance'] = 1\n",
        "  elif df.loc[i, 'importance'] == 3:\n",
        "    df.loc[i, 'importance'] = 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6584\n",
            "6582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRmgK3_cA2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fa8c9dae-c3df-46ac-e3a5-e7095b0f4c9d"
      },
      "source": [
        "#===============================================================================\n",
        "# Prepare text data (Title + summary) for the model\n",
        "#===============================================================================\n",
        "df['title_summary'] = df['title'] + ' ' + df['summary_v2']\n",
        "title_summary_len = [len(df['title_summary'][i].split(' ')) for i in range(len(df))]\n",
        "df_stat = pd.DataFrame(title_summary_len)\n",
        "df_stat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>52.518839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.800150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>47.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>183.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  6582.000000\n",
              "mean     52.518839\n",
              "std      17.800150\n",
              "min      13.000000\n",
              "25%      42.000000\n",
              "50%      47.000000\n",
              "75%      60.000000\n",
              "max     183.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_U1AzOCcBj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "44cbac53-9858-4a83-9d7c-7b3b9b8186ac"
      },
      "source": [
        "#===============================================================================\n",
        "# Data Preprocess & Distribution of labels (sentiment & importance)\n",
        "#===============================================================================\n",
        "X, y1, y2 = df['title_summary'], df['sentiment'], df['importance']\n",
        "y1_values, y2_values = y1.values, y2.values\n",
        "\n",
        "label_count_1, label_count_2 = [0,0,0], [0,0,0]\n",
        "for i in range(len(y1)):\n",
        "  label_count_1[y1_values[i]] += 1\n",
        "  label_count_2[y2_values[i]] += 1\n",
        "\n",
        "print(label_count_1, label_count_2)\n",
        "print([round(label_count_1[i]/sum(label_count_1),3) for i in range(len(label_count_1))], [round(label_count_2[i]/sum(label_count_2),3) for i in range(len(label_count_2))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1315, 3245, 2022] [2045, 2432, 2105]\n",
            "[0.2, 0.493, 0.307] [0.311, 0.369, 0.32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkZwef3vH1Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# In order to fine-tune BERT for the importance classification\n",
        "#===============================================================================\n",
        "X, y1, y2 = df['title_summary'], df['importance'], df['importance']\n",
        "y1_values, y2_values = y1.values, y2.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxLWWYR_cENN",
        "colab_type": "text"
      },
      "source": [
        "## 2. 토큰화 (Tokenization) 및 모델을 위한 전처리 <a class=\"anchor\" id=\"section_2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGcEWvPmcC8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "3375b025084944588359fa572d1132b5",
            "6879cbeaf7ad4a61ba6341319485b6b1",
            "4159ff445297463ca6508806862c7413",
            "c0a40a0911934e638f21077587cfa329",
            "37994fc0a3444d45b80bba87bf65a926",
            "96dce8b123584d98ab588864d8604307",
            "2369a730acab4d43ae06184b7085a626",
            "4faacd6a74f84ae7901a0e8ce201a476"
          ]
        },
        "outputId": "ebe65344-fc33-46c1-8b14-1bd31a9da0f4"
      },
      "source": [
        "#===============================================================================\n",
        "# Download BERT tokenizer from huggingface\n",
        "#===============================================================================\n",
        "from transformers import *\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', X[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(X[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3375b025084944588359fa572d1132b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Original:  Google Helping Mobile Publishing? Some Publishers Are Not So Sure In October, the software developer Alex Kras created a stir when he wrote a post titled “Google May Be Stealing Your Mobile Traffic,” in which he recounted what had happened when he used AMP on his technology blog. Joey Marburger, director of products for The Post, said that its readers were scrolling further on AMP stories, but that it was building its own fast system to gain greater control over ads and features. “\n",
            "Tokenized:  ['google', 'helping', 'mobile', 'publishing', '?', 'some', 'publishers', 'are', 'not', 'so', 'sure', 'in', 'october', ',', 'the', 'software', 'developer', 'alex', 'k', '##ras', 'created', 'a', 'stir', 'when', 'he', 'wrote', 'a', 'post', 'titled', '“', 'google', 'may', 'be', 'stealing', 'your', 'mobile', 'traffic', ',', '”', 'in', 'which', 'he', 'recounted', 'what', 'had', 'happened', 'when', 'he', 'used', 'amp', 'on', 'his', 'technology', 'blog', '.', 'joey', 'mar', '##burg', '##er', ',', 'director', 'of', 'products', 'for', 'the', 'post', ',', 'said', 'that', 'its', 'readers', 'were', 'scrolling', 'further', 'on', 'amp', 'stories', ',', 'but', 'that', 'it', 'was', 'building', 'its', 'own', 'fast', 'system', 'to', 'gain', 'greater', 'control', 'over', 'ads', 'and', 'features', '.', '“']\n",
            "Token IDs:  [8224, 5094, 4684, 4640, 1029, 2070, 8544, 2024, 2025, 2061, 2469, 1999, 2255, 1010, 1996, 4007, 9722, 4074, 1047, 8180, 2580, 1037, 16130, 2043, 2002, 2626, 1037, 2695, 4159, 1523, 8224, 2089, 2022, 11065, 2115, 4684, 4026, 1010, 1524, 1999, 2029, 2002, 22906, 2054, 2018, 3047, 2043, 2002, 2109, 23713, 2006, 2010, 2974, 9927, 1012, 9558, 9388, 4645, 2121, 1010, 2472, 1997, 3688, 2005, 1996, 2695, 1010, 2056, 2008, 2049, 8141, 2020, 28903, 2582, 2006, 23713, 3441, 1010, 2021, 2008, 2009, 2001, 2311, 2049, 2219, 3435, 2291, 2000, 5114, 3618, 2491, 2058, 14997, 1998, 2838, 1012, 1523]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_L8JkQvcG5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "f6dd1dfc-eb16-4daf-9a57-0dcf82d5e10c"
      },
      "source": [
        "#===============================================================================\n",
        "# In order to decide the MAX_LEN for padding and truncation purpose, check the \n",
        "# distribution of length of text data\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "max_len = 0\n",
        "too_big_input = []\n",
        "len_dist = []\n",
        "for i in range(len(X)):\n",
        "  input_ids = tokenizer.encode(X[i], add_special_tokens = True)\n",
        "  max_len = max(len(input_ids), max_len)\n",
        "  len_dist.append(len(input_ids))\n",
        "  if len(input_ids) > 512:\n",
        "    too_big_input.append(i)\n",
        "\n",
        "print('Max length of title is ', max_len)\n",
        "df_stat = pd.DataFrame(len_dist)\n",
        "df_stat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of title is  222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>69.756913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>23.331647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>62.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>222.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  6582.000000\n",
              "mean     69.756913\n",
              "std      23.331647\n",
              "min      17.000000\n",
              "25%      55.000000\n",
              "50%      62.000000\n",
              "75%      80.000000\n",
              "max     222.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fubqj_ccHpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# The preprocess code for the BERT\n",
        "# The following code is from https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "#===============================================================================\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "#The below code can be later modified to add the segment_id of setences. \n",
        "#However, since the summary + title data outperforms the validation accuracy from finBERT, I will modify this after implement the XLNet classifier\n",
        "\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            sent,  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "            truncation = True\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwloMBM7cUg-",
        "colab_type": "text"
      },
      "source": [
        "## 3. Fine-Tuning Function <a class=\"anchor\" id=\"section_3\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb5-9SCdcTjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Declare the BERT Classifier for later train and test purpose\n",
        "# if one wants to change the model, one can modify the below section\n",
        "#===============================================================================\n",
        "\n",
        "from torch import nn\n",
        "class BERT_KimCNN(nn.Module):\n",
        "  def __init__(self, embed_max_len, embed_dim, class_num, kernel_num, kernel_size, dropout, static, freeze_bert = False,layers_to_freeze = []):\n",
        "    super(BERT_KimCNN, self).__init__()\n",
        "    '''\n",
        "    embed_max_len: the max length of embedded vector\n",
        "    embed_dim: the output dimension of word vector (for BERT, 768)\n",
        "    class_num: the number of classes in the target\n",
        "    Co: number of filters to be applied\n",
        "    \n",
        "    Ks: the list of filter region sizes (will use [2,3,4])\n",
        "    '''\n",
        "    V = embed_max_len\n",
        "    D = embed_dim\n",
        "    C = class_num\n",
        "    Co = kernel_num\n",
        "    Ks = kernel_size\n",
        "\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    self.static = static\n",
        "    #Embedding for the convolutional layer\n",
        "    self.embed = nn.Embedding(V, D)\n",
        "    #Create 2D convolution for each filters\n",
        "    self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K,D)) for K in Ks])\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
        "    \n",
        "    #softmax function \n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    #Freeze the bert model\n",
        "    if freeze_bert:\n",
        "      for param in self.bert.parameters():\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "      if layers_to_freeze != []:\n",
        "        for i in layers_to_freeze:\n",
        "          for param in self.bert.encoder.layer[i].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    #Feed inputs to BERT\n",
        "    outputs = self.bert(input_ids = input_ids, \n",
        "                        attention_mask = attention_mask)\n",
        "    \n",
        "    # Extract the embedded word vectors for the convolutional layer\n",
        "    x = outputs[0]\n",
        "\n",
        "    if self.static:\n",
        "      x = Variable(x)\n",
        "    \n",
        "    x = x.unsqueeze(1)\n",
        "\n",
        "    x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "    x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "    x = torch.cat(x, 1)\n",
        "    x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "    \n",
        "    logit = self.fc1(x)  # (N, C)\n",
        "    \n",
        "    output = self.sigmoid(logit)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSerkyVXcXRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Initialize model for the later train purpose\n",
        "#===============================================================================\n",
        "\n",
        "def initialize_model(epochs=4, layers_to_freeze = []):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    embed_max_len = MAX_LEN\n",
        "    embed_dim = 768\n",
        "    class_num = 3\n",
        "    kernel_num = 4\n",
        "    kernel_size = [2,3,4,5]\n",
        "    dropout = 0.2\n",
        "    static = False\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_cnn = BERT_KimCNN(embed_max_len= embed_max_len,\n",
        "                           embed_dim = embed_dim,\n",
        "                           class_num = class_num,\n",
        "                           kernel_num = kernel_num,\n",
        "                           kernel_size = kernel_size,\n",
        "                           dropout = dropout,\n",
        "                           static = static,\n",
        "                           freeze_bert=False,\n",
        "                           layers_to_freeze = layers_to_freeze)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_cnn.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_cnn.parameters(),\n",
        "                      lr=6e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_cnn, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHssZER2cYV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# set_seed for reproducibility \n",
        "#===============================================================================\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5vaNfjFchDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Train & Evaluate function \n",
        "#===============================================================================\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    #return float(val_loss), float(val_accuracy)\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqfQKN92dCzJ",
        "colab_type": "text"
      },
      "source": [
        "## 4. Fine-Tuning <a class=\"anchor\" id=\"section_4\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkoMM3jddBkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5fb6d46c-04a1-4253-cdf6-263b2a7aaa27"
      },
      "source": [
        "#===============================================================================\n",
        "# Part where we train using the 5-fold cv\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "#train and val are indices\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 42)\n",
        "\n",
        "batch_size = 32\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "\n",
        "#y1 = y2.astype(int)\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "  #Data Preparation\n",
        "  X_train = X[train_index]\n",
        "  X_val = X[val_index]\n",
        "  y1_train = y1[train_index]\n",
        "  y1_val = y1[val_index]\n",
        "  \n",
        "  train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "  val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
        "  train_labels = torch.tensor(y1_train.values)\n",
        "  val_labels = torch.tensor(y1_val.values)\n",
        "  \n",
        "  #Data Loader Class\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "  val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "  val_sampler = RandomSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n",
        "\n",
        "  #Fine Tune and Evaluation\n",
        "  set_seed(42)    # Set seed for reproducibility\n",
        "  bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
        "  val_loss1, val_accuracy1 = train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)\n",
        "  \n",
        "  val_loss.append(val_loss1)\n",
        "  val_accuracy.append(val_accuracy1)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.055753   |     -      |     -     |   15.88  \n",
            "   1    |   40    |   1.032163   |     -      |     -     |   15.59  \n",
            "   1    |   60    |   0.991137   |     -      |     -     |   14.92  \n",
            "   1    |   80    |   0.976826   |     -      |     -     |   14.51  \n",
            "   1    |   100   |   0.959184   |     -      |     -     |   14.49  \n",
            "   1    |   120   |   0.957716   |     -      |     -     |   14.72  \n",
            "   1    |   140   |   0.961850   |     -      |     -     |   14.96  \n",
            "   1    |   160   |   0.921913   |     -      |     -     |   14.97  \n",
            "   1    |   164   |   0.886662   |     -      |     -     |   2.66   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.980201   |  0.923920  |   53.02   |  133.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.924773   |     -      |     -     |   15.52  \n",
            "   2    |   40    |   0.909730   |     -      |     -     |   14.77  \n",
            "   2    |   60    |   0.893421   |     -      |     -     |   14.80  \n",
            "   2    |   80    |   0.884407   |     -      |     -     |   14.85  \n",
            "   2    |   100   |   0.867391   |     -      |     -     |   14.89  \n",
            "   2    |   120   |   0.874900   |     -      |     -     |   14.91  \n",
            "   2    |   140   |   0.887880   |     -      |     -     |   14.92  \n",
            "   2    |   160   |   0.856712   |     -      |     -     |   14.88  \n",
            "   2    |   164   |   0.864563   |     -      |     -     |   2.67   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.887075   |  0.907179  |   60.92   |  132.92  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.843611   |     -      |     -     |   15.65  \n",
            "   3    |   40    |   0.814694   |     -      |     -     |   14.86  \n",
            "   3    |   60    |   0.822039   |     -      |     -     |   14.88  \n",
            "   3    |   80    |   0.813356   |     -      |     -     |   14.83  \n",
            "   3    |   100   |   0.795174   |     -      |     -     |   14.84  \n",
            "   3    |   120   |   0.799726   |     -      |     -     |   14.84  \n",
            "   3    |   140   |   0.798884   |     -      |     -     |   14.83  \n",
            "   3    |   160   |   0.797825   |     -      |     -     |   14.80  \n",
            "   3    |   164   |   0.802559   |     -      |     -     |   2.65   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.810667   |  0.898724  |   62.92   |  132.85  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.761735   |     -      |     -     |   15.53  \n",
            "   4    |   40    |   0.740767   |     -      |     -     |   14.72  \n",
            "   4    |   60    |   0.740132   |     -      |     -     |   14.78  \n",
            "   4    |   80    |   0.761034   |     -      |     -     |   14.90  \n",
            "   4    |   100   |   0.739721   |     -      |     -     |   15.00  \n",
            "   4    |   120   |   0.740456   |     -      |     -     |   14.91  \n",
            "   4    |   140   |   0.741466   |     -      |     -     |   14.68  \n",
            "   4    |   160   |   0.744649   |     -      |     -     |   14.65  \n",
            "   4    |   164   |   0.799288   |     -      |     -     |   2.64   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   0.747625   |  0.890200  |   65.07   |  132.47  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykoS1FN_dM6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a43a1ba5-3889-45c4-ad65-9eb3ab74732b"
      },
      "source": [
        "#===============================================================================\n",
        "# Print the mean loss and accuracy of the 5-fold cv\n",
        "#===============================================================================\n",
        "print('The mean validation accuracy of 5-fold cv is: ',np.mean(val_accuracy))\n",
        "print('The mean validation loss of 5-fold cv is: ', np.mean(val_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean validation accuracy of 5-fold cv is:  65.07440476190476\n",
            "The mean validation loss of 5-fold cv is:  0.8901995789437067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdh0TZ4MdMQ4",
        "colab_type": "text"
      },
      "source": [
        "## 5. Confusion matrix와 치명 오답률 <a class=\"anchor\" id=\"section_5\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz-hjfIZdGHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Prediction function given the fine-tuned model\n",
        "#===============================================================================\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    val_accuracy = []\n",
        "    all_pred = []\n",
        "    all_real = []\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "        all_real.append(b_labels)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        all_pred.append(preds)\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    all_real = torch.cat(all_real)\n",
        "    all_pred = torch.cat(all_pred)\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    #val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_accuracy,all_real, all_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VButRqagdRn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Import py file for confusion matrtix\n",
        "#===============================================================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from confusion_matrix import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nj4BficdRvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5c1bf5ec-e641-4570-b721-114b256d66f8"
      },
      "source": [
        "#===============================================================================\n",
        "# Make prediction for confusion matrix and critical error\n",
        "#===============================================================================\n",
        "\n",
        "acc,all_real, all_pred = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "critical_error = 0\n",
        "crit_error_index = []\n",
        "hit = 0\n",
        "for i in range(len(all_real)):\n",
        "  if all_real[i] == all_pred[i]:\n",
        "    hit += 1\n",
        "  if abs(all_pred[i] - all_real[i]) == 2:\n",
        "    critical_error += 1\n",
        "    crit_error_index.append(i)\n",
        "\n",
        "all_pred = all_pred.cpu().numpy()\n",
        "all_real = all_real.cpu().numpy()\n",
        "\n",
        "print('The accuracy of the model is :', hit/len(all_real))\n",
        "print('The critical error is : ',critical_error/len(all_real))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model is : 0.6476841305998481\n",
            "The critical error is :  0.03492786636294609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeFErZ1XdSbV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "15bd1d3d-955b-4ccc-ee1d-74ff6d7cf1ae"
      },
      "source": [
        "#===============================================================================\n",
        "# Visualization of Confusion matrix\n",
        "#===============================================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_real, all_pred)\n",
        "plot_confusion_matrix(cm,\n",
        "                      ['neg','neu', 'pos'],\n",
        "                      title='Confusion matrix',\n",
        "                      cmap=None,\n",
        "                      normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr6di4_gME7G",
        "colab_type": "text"
      },
      "source": [
        "## Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BjKjDHDMCM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d374e020-3ddd-47a2-c9e3-32eb49e34ea9"
      },
      "source": [
        "#===============================================================================\n",
        "# import py for the EDA (Easy data Augmentation)\n",
        "# original code from https://github.com/jasonwei20/eda_nlp\n",
        "#===============================================================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from easy_data_augmentation import *\n",
        "\n",
        "X, y1 = gen_eda(X, y1, alpha = 0.2, num_aug = 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uFA0mVX1Tty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bab3658a665b4c4881c7425872507e2f",
            "d2221167ac6948bfb16710269381a0f0",
            "297651a41f1e4ceaae7937f5678e5577",
            "6dd2d01b3e834121bdb207f7a3b89da5",
            "90348a81cc0644bbacc58881547384d7",
            "317e49802f2849a1813dc7fa7e177c26",
            "c555dbd8f8404c7e9df9f54f8214536b",
            "ab7533ff2c28470a8270f1f859f03f6b",
            "c4a846fe557342d7b3f6722e0369802f",
            "073a29d4b7dd479885495858b199960d",
            "c0fcc534bee043759a2cf9abba84485d",
            "8a57dbf12c0b438497c7b983e9055e83",
            "4a4a50981d8345638c91c423a342ee61",
            "8831987828a54a11950099a8e36850ab",
            "d2f58b32552140658b51c56e7c1575fc",
            "8f84be6879a642b7b3b3173309e1becf"
          ]
        },
        "outputId": "64af4293-b723-450e-838b-b497f45f4f6d"
      },
      "source": [
        "#===============================================================================\n",
        "# Train for prediction\n",
        "#===============================================================================\n",
        "\n",
        "batch_size = 32\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_inputs, train_masks = preprocessing_for_bert(X)\n",
        "train_labels = torch.tensor(y1)\n",
        "#Data Loader Class\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=4, layers_to_freeze= [0,1,2,3,4,5,6,7])\n",
        "train(bert_classifier, train_dataloader, epochs=4, evaluation=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bab3658a665b4c4881c7425872507e2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4a846fe557342d7b3f6722e0369802f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.092773   |     -      |     -     |   11.84  \n",
            "   1    |   40    |   1.077763   |     -      |     -     |   11.18  \n",
            "   1    |   60    |   1.069973   |     -      |     -     |   11.42  \n",
            "   1    |   80    |   1.044242   |     -      |     -     |   11.81  \n",
            "   1    |   100   |   1.039094   |     -      |     -     |   12.27  \n",
            "   1    |   120   |   0.994135   |     -      |     -     |   12.30  \n",
            "   1    |   140   |   1.002224   |     -      |     -     |   11.91  \n",
            "   1    |   160   |   0.986734   |     -      |     -     |   11.70  \n",
            "   1    |   180   |   0.984114   |     -      |     -     |   11.62  \n",
            "   1    |   200   |   0.983747   |     -      |     -     |   11.70  \n",
            "   1    |   220   |   0.976276   |     -      |     -     |   11.76  \n",
            "   1    |   240   |   0.977112   |     -      |     -     |   11.92  \n",
            "   1    |   260   |   0.989584   |     -      |     -     |   11.93  \n",
            "   1    |   280   |   0.954081   |     -      |     -     |   11.86  \n",
            "   1    |   300   |   0.939533   |     -      |     -     |   11.78  \n",
            "   1    |   320   |   0.948313   |     -      |     -     |   11.75  \n",
            "   1    |   340   |   0.944590   |     -      |     -     |   11.76  \n",
            "   1    |   360   |   0.945270   |     -      |     -     |   11.77  \n",
            "   1    |   380   |   0.952154   |     -      |     -     |   11.80  \n",
            "   1    |   400   |   0.944281   |     -      |     -     |   11.83  \n",
            "   1    |   420   |   0.918529   |     -      |     -     |   11.85  \n",
            "   1    |   440   |   0.916626   |     -      |     -     |   11.85  \n",
            "   1    |   460   |   0.927602   |     -      |     -     |   11.88  \n",
            "   1    |   480   |   0.914099   |     -      |     -     |   11.84  \n",
            "   1    |   500   |   0.896988   |     -      |     -     |   11.87  \n",
            "   1    |   520   |   0.931457   |     -      |     -     |   11.87  \n",
            "   1    |   540   |   0.899203   |     -      |     -     |   11.83  \n",
            "   1    |   560   |   0.893480   |     -      |     -     |   11.80  \n",
            "   1    |   580   |   0.903732   |     -      |     -     |   11.75  \n",
            "   1    |   600   |   0.911462   |     -      |     -     |   11.81  \n",
            "   1    |   620   |   0.915914   |     -      |     -     |   11.86  \n",
            "   1    |   640   |   0.883457   |     -      |     -     |   11.95  \n",
            "   1    |   660   |   0.891896   |     -      |     -     |   11.91  \n",
            "   1    |   680   |   0.882655   |     -      |     -     |   11.91  \n",
            "   1    |   700   |   0.906880   |     -      |     -     |   11.84  \n",
            "   1    |   720   |   0.888929   |     -      |     -     |   11.88  \n",
            "   1    |   740   |   0.877222   |     -      |     -     |   11.87  \n",
            "   1    |   760   |   0.893187   |     -      |     -     |   11.86  \n",
            "   1    |   780   |   0.878624   |     -      |     -     |   11.88  \n",
            "   1    |   800   |   0.895283   |     -      |     -     |   11.87  \n",
            "   1    |   820   |   0.879959   |     -      |     -     |   11.86  \n",
            "   1    |   840   |   0.889403   |     -      |     -     |   11.87  \n",
            "   1    |   860   |   0.902149   |     -      |     -     |   11.81  \n",
            "   1    |   880   |   0.889117   |     -      |     -     |   11.85  \n",
            "   1    |   900   |   0.866811   |     -      |     -     |   11.84  \n",
            "   1    |   920   |   0.856711   |     -      |     -     |   11.82  \n",
            "   1    |   940   |   0.855463   |     -      |     -     |   11.80  \n",
            "   1    |   960   |   0.852567   |     -      |     -     |   11.82  \n",
            "   1    |   980   |   0.878995   |     -      |     -     |   11.77  \n",
            "   1    |  1000   |   0.874237   |     -      |     -     |   11.80  \n",
            "   1    |  1020   |   0.866245   |     -      |     -     |   11.78  \n",
            "   1    |  1040   |   0.862837   |     -      |     -     |   11.80  \n",
            "   1    |  1060   |   0.849866   |     -      |     -     |   11.80  \n",
            "   1    |  1080   |   0.855137   |     -      |     -     |   11.78  \n",
            "   1    |  1100   |   0.849635   |     -      |     -     |   11.83  \n",
            "   1    |  1120   |   0.846868   |     -      |     -     |   11.79  \n",
            "   1    |  1140   |   0.860277   |     -      |     -     |   11.83  \n",
            "   1    |  1160   |   0.848064   |     -      |     -     |   11.82  \n",
            "   1    |  1180   |   0.857096   |     -      |     -     |   11.84  \n",
            "   1    |  1200   |   0.853955   |     -      |     -     |   11.88  \n",
            "   1    |  1220   |   0.874492   |     -      |     -     |   11.83  \n",
            "   1    |  1240   |   0.852725   |     -      |     -     |   11.86  \n",
            "   1    |  1260   |   0.817433   |     -      |     -     |   11.87  \n",
            "   1    |  1280   |   0.811751   |     -      |     -     |   11.92  \n",
            "   1    |  1300   |   0.839685   |     -      |     -     |   11.92  \n",
            "   1    |  1320   |   0.833248   |     -      |     -     |   11.90  \n",
            "   1    |  1340   |   0.817165   |     -      |     -     |   11.90  \n",
            "   1    |  1360   |   0.849392   |     -      |     -     |   11.90  \n",
            "   1    |  1380   |   0.809615   |     -      |     -     |   11.90  \n",
            "   1    |  1400   |   0.835757   |     -      |     -     |   11.86  \n",
            "   1    |  1420   |   0.834706   |     -      |     -     |   11.86  \n",
            "   1    |  1439   |   0.831329   |     -      |     -     |   11.17  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.781382   |     -      |     -     |   12.45  \n",
            "   2    |   40    |   0.788307   |     -      |     -     |   11.85  \n",
            "   2    |   60    |   0.797558   |     -      |     -     |   11.85  \n",
            "   2    |   80    |   0.791288   |     -      |     -     |   11.82  \n",
            "   2    |   100   |   0.807960   |     -      |     -     |   11.80  \n",
            "   2    |   120   |   0.784783   |     -      |     -     |   11.82  \n",
            "   2    |   140   |   0.772754   |     -      |     -     |   11.81  \n",
            "   2    |   160   |   0.800058   |     -      |     -     |   11.82  \n",
            "   2    |   180   |   0.798905   |     -      |     -     |   11.79  \n",
            "   2    |   200   |   0.800644   |     -      |     -     |   11.82  \n",
            "   2    |   220   |   0.795159   |     -      |     -     |   11.82  \n",
            "   2    |   240   |   0.764772   |     -      |     -     |   11.78  \n",
            "   2    |   260   |   0.775627   |     -      |     -     |   11.80  \n",
            "   2    |   280   |   0.777273   |     -      |     -     |   11.83  \n",
            "   2    |   300   |   0.768944   |     -      |     -     |   11.79  \n",
            "   2    |   320   |   0.800979   |     -      |     -     |   11.79  \n",
            "   2    |   340   |   0.778568   |     -      |     -     |   11.78  \n",
            "   2    |   360   |   0.770769   |     -      |     -     |   11.78  \n",
            "   2    |   380   |   0.765233   |     -      |     -     |   11.84  \n",
            "   2    |   400   |   0.760540   |     -      |     -     |   11.81  \n",
            "   2    |   420   |   0.763567   |     -      |     -     |   11.82  \n",
            "   2    |   440   |   0.762175   |     -      |     -     |   11.82  \n",
            "   2    |   460   |   0.756250   |     -      |     -     |   11.85  \n",
            "   2    |   480   |   0.778747   |     -      |     -     |   11.84  \n",
            "   2    |   500   |   0.758527   |     -      |     -     |   11.86  \n",
            "   2    |   520   |   0.763573   |     -      |     -     |   11.83  \n",
            "   2    |   540   |   0.788125   |     -      |     -     |   11.87  \n",
            "   2    |   560   |   0.762138   |     -      |     -     |   11.89  \n",
            "   2    |   580   |   0.770654   |     -      |     -     |   11.87  \n",
            "   2    |   600   |   0.776577   |     -      |     -     |   11.91  \n",
            "   2    |   620   |   0.760184   |     -      |     -     |   11.89  \n",
            "   2    |   640   |   0.796247   |     -      |     -     |   11.87  \n",
            "   2    |   660   |   0.744544   |     -      |     -     |   11.88  \n",
            "   2    |   680   |   0.771719   |     -      |     -     |   11.91  \n",
            "   2    |   700   |   0.764311   |     -      |     -     |   11.92  \n",
            "   2    |   720   |   0.750153   |     -      |     -     |   11.89  \n",
            "   2    |   740   |   0.788232   |     -      |     -     |   11.88  \n",
            "   2    |   760   |   0.750120   |     -      |     -     |   11.89  \n",
            "   2    |   780   |   0.754005   |     -      |     -     |   11.92  \n",
            "   2    |   800   |   0.745470   |     -      |     -     |   11.90  \n",
            "   2    |   820   |   0.785494   |     -      |     -     |   11.90  \n",
            "   2    |   840   |   0.773510   |     -      |     -     |   11.90  \n",
            "   2    |   860   |   0.754332   |     -      |     -     |   11.90  \n",
            "   2    |   880   |   0.735041   |     -      |     -     |   11.88  \n",
            "   2    |   900   |   0.746783   |     -      |     -     |   11.87  \n",
            "   2    |   920   |   0.756958   |     -      |     -     |   11.93  \n",
            "   2    |   940   |   0.742591   |     -      |     -     |   11.90  \n",
            "   2    |   960   |   0.755275   |     -      |     -     |   11.86  \n",
            "   2    |   980   |   0.767054   |     -      |     -     |   11.88  \n",
            "   2    |  1000   |   0.734128   |     -      |     -     |   11.85  \n",
            "   2    |  1020   |   0.720459   |     -      |     -     |   11.88  \n",
            "   2    |  1040   |   0.750368   |     -      |     -     |   11.87  \n",
            "   2    |  1060   |   0.740736   |     -      |     -     |   11.84  \n",
            "   2    |  1080   |   0.728481   |     -      |     -     |   11.83  \n",
            "   2    |  1100   |   0.767307   |     -      |     -     |   11.82  \n",
            "   2    |  1120   |   0.756132   |     -      |     -     |   11.83  \n",
            "   2    |  1140   |   0.760965   |     -      |     -     |   11.82  \n",
            "   2    |  1160   |   0.716135   |     -      |     -     |   11.85  \n",
            "   2    |  1180   |   0.739053   |     -      |     -     |   11.78  \n",
            "   2    |  1200   |   0.718176   |     -      |     -     |   11.80  \n",
            "   2    |  1220   |   0.729544   |     -      |     -     |   11.81  \n",
            "   2    |  1240   |   0.737487   |     -      |     -     |   11.84  \n",
            "   2    |  1260   |   0.734117   |     -      |     -     |   11.84  \n",
            "   2    |  1280   |   0.744771   |     -      |     -     |   11.85  \n",
            "   2    |  1300   |   0.727697   |     -      |     -     |   11.85  \n",
            "   2    |  1320   |   0.721822   |     -      |     -     |   11.86  \n",
            "   2    |  1340   |   0.713545   |     -      |     -     |   11.89  \n",
            "   2    |  1360   |   0.747678   |     -      |     -     |   11.86  \n",
            "   2    |  1380   |   0.731735   |     -      |     -     |   11.87  \n",
            "   2    |  1400   |   0.725277   |     -      |     -     |   11.89  \n",
            "   2    |  1420   |   0.737271   |     -      |     -     |   11.89  \n",
            "   2    |  1439   |   0.729558   |     -      |     -     |   11.20  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.706224   |     -      |     -     |   12.50  \n",
            "   3    |   40    |   0.700381   |     -      |     -     |   11.88  \n",
            "   3    |   60    |   0.721194   |     -      |     -     |   11.91  \n",
            "   3    |   80    |   0.692349   |     -      |     -     |   11.91  \n",
            "   3    |   100   |   0.705852   |     -      |     -     |   11.93  \n",
            "   3    |   120   |   0.701374   |     -      |     -     |   11.93  \n",
            "   3    |   140   |   0.691348   |     -      |     -     |   11.93  \n",
            "   3    |   160   |   0.711250   |     -      |     -     |   11.92  \n",
            "   3    |   180   |   0.732411   |     -      |     -     |   11.91  \n",
            "   3    |   200   |   0.693626   |     -      |     -     |   11.90  \n",
            "   3    |   220   |   0.705253   |     -      |     -     |   11.92  \n",
            "   3    |   240   |   0.698653   |     -      |     -     |   11.95  \n",
            "   3    |   260   |   0.718583   |     -      |     -     |   11.91  \n",
            "   3    |   280   |   0.704579   |     -      |     -     |   11.94  \n",
            "   3    |   300   |   0.686309   |     -      |     -     |   11.92  \n",
            "   3    |   320   |   0.683633   |     -      |     -     |   11.91  \n",
            "   3    |   340   |   0.687814   |     -      |     -     |   11.91  \n",
            "   3    |   360   |   0.694687   |     -      |     -     |   11.94  \n",
            "   3    |   380   |   0.721946   |     -      |     -     |   11.93  \n",
            "   3    |   400   |   0.691021   |     -      |     -     |   11.92  \n",
            "   3    |   420   |   0.718088   |     -      |     -     |   11.91  \n",
            "   3    |   440   |   0.700612   |     -      |     -     |   11.88  \n",
            "   3    |   460   |   0.696992   |     -      |     -     |   11.84  \n",
            "   3    |   480   |   0.700593   |     -      |     -     |   11.86  \n",
            "   3    |   500   |   0.724171   |     -      |     -     |   11.85  \n",
            "   3    |   520   |   0.695219   |     -      |     -     |   11.84  \n",
            "   3    |   540   |   0.708637   |     -      |     -     |   11.81  \n",
            "   3    |   560   |   0.688630   |     -      |     -     |   11.82  \n",
            "   3    |   580   |   0.685364   |     -      |     -     |   11.83  \n",
            "   3    |   600   |   0.702028   |     -      |     -     |   11.83  \n",
            "   3    |   620   |   0.678065   |     -      |     -     |   11.78  \n",
            "   3    |   640   |   0.707633   |     -      |     -     |   11.86  \n",
            "   3    |   660   |   0.705869   |     -      |     -     |   11.88  \n",
            "   3    |   680   |   0.707953   |     -      |     -     |   11.85  \n",
            "   3    |   700   |   0.701864   |     -      |     -     |   11.85  \n",
            "   3    |   720   |   0.706451   |     -      |     -     |   11.85  \n",
            "   3    |   740   |   0.724165   |     -      |     -     |   11.90  \n",
            "   3    |   760   |   0.715942   |     -      |     -     |   11.90  \n",
            "   3    |   780   |   0.687357   |     -      |     -     |   11.88  \n",
            "   3    |   800   |   0.711519   |     -      |     -     |   11.90  \n",
            "   3    |   820   |   0.704810   |     -      |     -     |   11.91  \n",
            "   3    |   840   |   0.700442   |     -      |     -     |   11.89  \n",
            "   3    |   860   |   0.699852   |     -      |     -     |   11.91  \n",
            "   3    |   880   |   0.673555   |     -      |     -     |   11.90  \n",
            "   3    |   900   |   0.695168   |     -      |     -     |   11.93  \n",
            "   3    |   920   |   0.698545   |     -      |     -     |   11.95  \n",
            "   3    |   940   |   0.684364   |     -      |     -     |   11.90  \n",
            "   3    |   960   |   0.669485   |     -      |     -     |   11.91  \n",
            "   3    |   980   |   0.682107   |     -      |     -     |   11.86  \n",
            "   3    |  1000   |   0.707789   |     -      |     -     |   11.90  \n",
            "   3    |  1020   |   0.695409   |     -      |     -     |   11.90  \n",
            "   3    |  1040   |   0.708298   |     -      |     -     |   11.84  \n",
            "   3    |  1060   |   0.679650   |     -      |     -     |   11.86  \n",
            "   3    |  1080   |   0.698577   |     -      |     -     |   11.82  \n",
            "   3    |  1100   |   0.696897   |     -      |     -     |   11.86  \n",
            "   3    |  1120   |   0.694131   |     -      |     -     |   11.84  \n",
            "   3    |  1140   |   0.697347   |     -      |     -     |   11.82  \n",
            "   3    |  1160   |   0.683733   |     -      |     -     |   11.81  \n",
            "   3    |  1180   |   0.704307   |     -      |     -     |   11.82  \n",
            "   3    |  1200   |   0.688903   |     -      |     -     |   11.85  \n",
            "   3    |  1220   |   0.651484   |     -      |     -     |   11.82  \n",
            "   3    |  1240   |   0.673121   |     -      |     -     |   11.82  \n",
            "   3    |  1260   |   0.685190   |     -      |     -     |   11.83  \n",
            "   3    |  1280   |   0.693487   |     -      |     -     |   11.84  \n",
            "   3    |  1300   |   0.673240   |     -      |     -     |   11.82  \n",
            "   3    |  1320   |   0.695431   |     -      |     -     |   11.84  \n",
            "   3    |  1340   |   0.698067   |     -      |     -     |   11.83  \n",
            "   3    |  1360   |   0.720567   |     -      |     -     |   11.80  \n",
            "   3    |  1380   |   0.672814   |     -      |     -     |   11.83  \n",
            "   3    |  1400   |   0.687626   |     -      |     -     |   11.84  \n",
            "   3    |  1420   |   0.677667   |     -      |     -     |   11.85  \n",
            "   3    |  1439   |   0.678249   |     -      |     -     |   11.14  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.663316   |     -      |     -     |   12.41  \n",
            "   4    |   40    |   0.686427   |     -      |     -     |   11.84  \n",
            "   4    |   60    |   0.687170   |     -      |     -     |   11.84  \n",
            "   4    |   80    |   0.698597   |     -      |     -     |   11.86  \n",
            "   4    |   100   |   0.661614   |     -      |     -     |   11.85  \n",
            "   4    |   120   |   0.655862   |     -      |     -     |   11.85  \n",
            "   4    |   140   |   0.686834   |     -      |     -     |   11.85  \n",
            "   4    |   160   |   0.670101   |     -      |     -     |   11.83  \n",
            "   4    |   180   |   0.686062   |     -      |     -     |   11.85  \n",
            "   4    |   200   |   0.684467   |     -      |     -     |   11.84  \n",
            "   4    |   220   |   0.684081   |     -      |     -     |   11.83  \n",
            "   4    |   240   |   0.673439   |     -      |     -     |   11.86  \n",
            "   4    |   260   |   0.669805   |     -      |     -     |   11.83  \n",
            "   4    |   280   |   0.678108   |     -      |     -     |   11.80  \n",
            "   4    |   300   |   0.685998   |     -      |     -     |   11.85  \n",
            "   4    |   320   |   0.653574   |     -      |     -     |   11.84  \n",
            "   4    |   340   |   0.668674   |     -      |     -     |   11.85  \n",
            "   4    |   360   |   0.666343   |     -      |     -     |   11.86  \n",
            "   4    |   380   |   0.667594   |     -      |     -     |   11.82  \n",
            "   4    |   400   |   0.674789   |     -      |     -     |   11.87  \n",
            "   4    |   420   |   0.683120   |     -      |     -     |   11.82  \n",
            "   4    |   440   |   0.649340   |     -      |     -     |   11.83  \n",
            "   4    |   460   |   0.679263   |     -      |     -     |   11.83  \n",
            "   4    |   480   |   0.670423   |     -      |     -     |   11.83  \n",
            "   4    |   500   |   0.681115   |     -      |     -     |   11.83  \n",
            "   4    |   520   |   0.664254   |     -      |     -     |   11.88  \n",
            "   4    |   540   |   0.663827   |     -      |     -     |   11.85  \n",
            "   4    |   560   |   0.656959   |     -      |     -     |   11.84  \n",
            "   4    |   580   |   0.659631   |     -      |     -     |   11.81  \n",
            "   4    |   600   |   0.669429   |     -      |     -     |   11.81  \n",
            "   4    |   620   |   0.663557   |     -      |     -     |   11.84  \n",
            "   4    |   640   |   0.670261   |     -      |     -     |   11.83  \n",
            "   4    |   660   |   0.665389   |     -      |     -     |   11.84  \n",
            "   4    |   680   |   0.659846   |     -      |     -     |   11.80  \n",
            "   4    |   700   |   0.658529   |     -      |     -     |   11.86  \n",
            "   4    |   720   |   0.679434   |     -      |     -     |   11.83  \n",
            "   4    |   740   |   0.665408   |     -      |     -     |   11.84  \n",
            "   4    |   760   |   0.654068   |     -      |     -     |   11.82  \n",
            "   4    |   780   |   0.680901   |     -      |     -     |   11.82  \n",
            "   4    |   800   |   0.680699   |     -      |     -     |   11.85  \n",
            "   4    |   820   |   0.671190   |     -      |     -     |   11.83  \n",
            "   4    |   840   |   0.649503   |     -      |     -     |   11.82  \n",
            "   4    |   860   |   0.663437   |     -      |     -     |   11.85  \n",
            "   4    |   880   |   0.668722   |     -      |     -     |   11.84  \n",
            "   4    |   900   |   0.682670   |     -      |     -     |   11.83  \n",
            "   4    |   920   |   0.652393   |     -      |     -     |   11.82  \n",
            "   4    |   940   |   0.671376   |     -      |     -     |   11.84  \n",
            "   4    |   960   |   0.652328   |     -      |     -     |   11.84  \n",
            "   4    |   980   |   0.663878   |     -      |     -     |   11.84  \n",
            "   4    |  1000   |   0.662092   |     -      |     -     |   11.87  \n",
            "   4    |  1020   |   0.662805   |     -      |     -     |   11.81  \n",
            "   4    |  1040   |   0.652321   |     -      |     -     |   11.81  \n",
            "   4    |  1060   |   0.667000   |     -      |     -     |   11.86  \n",
            "   4    |  1080   |   0.656897   |     -      |     -     |   11.86  \n",
            "   4    |  1100   |   0.679157   |     -      |     -     |   11.86  \n",
            "   4    |  1120   |   0.667671   |     -      |     -     |   11.85  \n",
            "   4    |  1140   |   0.652332   |     -      |     -     |   11.86  \n",
            "   4    |  1160   |   0.663395   |     -      |     -     |   11.84  \n",
            "   4    |  1180   |   0.660689   |     -      |     -     |   11.89  \n",
            "   4    |  1200   |   0.660261   |     -      |     -     |   11.86  \n",
            "   4    |  1220   |   0.651345   |     -      |     -     |   11.89  \n",
            "   4    |  1240   |   0.671628   |     -      |     -     |   11.86  \n",
            "   4    |  1260   |   0.655533   |     -      |     -     |   11.84  \n",
            "   4    |  1280   |   0.673986   |     -      |     -     |   11.86  \n",
            "   4    |  1300   |   0.663516   |     -      |     -     |   11.87  \n",
            "   4    |  1320   |   0.648895   |     -      |     -     |   11.87  \n",
            "   4    |  1340   |   0.656923   |     -      |     -     |   11.89  \n",
            "   4    |  1360   |   0.666743   |     -      |     -     |   11.83  \n",
            "   4    |  1380   |   0.651496   |     -      |     -     |   11.83  \n",
            "   4    |  1400   |   0.675424   |     -      |     -     |   11.82  \n",
            "   4    |  1420   |   0.678614   |     -      |     -     |   11.87  \n",
            "   4    |  1439   |   0.668544   |     -      |     -     |   11.17  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hJhIztyMKMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Prediction function \n",
        "#===============================================================================\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    val_accuracy = []\n",
        "    all_pred = []\n",
        "    all_real = []\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "        all_real.append(b_labels)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        all_pred.append(preds)\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    all_real = torch.cat(all_real)\n",
        "    all_pred = torch.cat(all_pred)\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    #val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_accuracy,all_real, all_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxcdEhYmMLZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "b68920b5-6309-4a5c-803c-0bf420d91972"
      },
      "source": [
        "#===============================================================================\n",
        "# Test the trained model\n",
        "#===============================================================================\n",
        "df_test = pd.read_json('/content/drive/My Drive/KIS data/test_data.json')\n",
        "\n",
        "print(len(df_test))\n",
        "idx_to_remove = []\n",
        "for i in range(len(df_test)):\n",
        "  if type(df_test['summary'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "  if type(df_test['title'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "\n",
        "df_test = df_test.iloc[list(set(df_test.index) - set(idx_to_remove))]\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_test['title_summary'] = df_test['title'] + ' ' + df_test['summary']\n",
        "df_test= df_test.drop(df_test[df_test['title_summary'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "df_test= df_test.drop(df_test[df_test['importance'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "df_test= df_test.drop(df_test[df_test['sentiment'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "title_summary_len = [len(df_test['title_summary'][i].split(' ')) for i in range(len(df_test))]\n",
        "df_stat = pd.DataFrame(title_summary_len)\n",
        "df_stat.describe()\n",
        "print(len(df_test))\n",
        "\n",
        "X_test, y1_test, y2_test = df_test['title_summary'], df_test['sentiment'].apply(int), df_test['importance'].apply(int)\n",
        "y1_test_values, y2_test_values = y1_test.values, y2_test.values\n",
        "\n",
        "label_count_test_1, label_count_test_2 = [0,0,0], [0,0,0]\n",
        "for i in range(len(y1_test)):\n",
        "  label_count_test_1[y1_test_values[i]] += 1\n",
        "  label_count_test_2[y2_test_values[i]] += 1\n",
        "\n",
        "print(label_count_test_1, label_count_test_2)\n",
        "print([round(label_count_test_1[i]/sum(label_count_test_1),3) for i in range(len(label_count_test_1))], [round(label_count_test_2[i]/sum(label_count_test_2),3) for i in range(len(label_count_test_2))])\n",
        "\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "test_labels = torch.tensor(y1_test)\n",
        "#Data Loader Class\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)\n",
        "\n",
        "acc,all_real, all_pred = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "critical_error = 0\n",
        "crit_error_index = []\n",
        "hit = 0\n",
        "for i in range(len(all_real)):\n",
        "  if all_real[i] == all_pred[i]:\n",
        "    hit += 1\n",
        "  if abs(all_pred[i] - all_real[i]) == 2:\n",
        "    critical_error += 1\n",
        "    crit_error_index.append(i)\n",
        "\n",
        "all_pred = all_pred.cpu().numpy()\n",
        "all_real = all_real.cpu().numpy()\n",
        "\n",
        "print('The accuracy of the model is :', hit/len(all_real))\n",
        "print('The critical error is : ',critical_error/len(all_real))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2898\n",
            "2866\n",
            "[366, 1585, 915] [1052, 918, 896]\n",
            "[0.128, 0.553, 0.319] [0.367, 0.32, 0.313]\n",
            "The accuracy of the model is : 0.35101186322400557\n",
            "The critical error is :  0.14166085136078158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89_4PDCoMMT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from confusion_matrix import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeTJ7jKJMNXy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "4939afa5-4fca-4378-a23b-0147454ee97d"
      },
      "source": [
        "#===============================================================================\n",
        "# Visualization of confusion matrix\n",
        "#===============================================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_real, all_pred)\n",
        "plot_confusion_matrix(cm,\n",
        "                      ['neg','neu', 'pos'],\n",
        "                      title='Confusion matrix',\n",
        "                      cmap=None,\n",
        "                      normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}