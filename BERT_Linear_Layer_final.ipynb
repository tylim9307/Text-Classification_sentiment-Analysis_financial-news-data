{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Linear_Layer_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b6a6ca8dfc64650ba2c95f6a8f65cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9880d182f7634adebccd143fc336b4ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd38a78cfc1c455cb576e91f20b33654",
              "IPY_MODEL_a972da2bc6d349e5a22f35af7c13af48"
            ]
          }
        },
        "9880d182f7634adebccd143fc336b4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd38a78cfc1c455cb576e91f20b33654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb7b6270613649eebe7cd2e3923272a4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75ef76b0656e468bb084290dbba7061a"
          }
        },
        "a972da2bc6d349e5a22f35af7c13af48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d3a09f060095446ab1aab0f411a3714f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 915kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4982aaf88ea94b9480dd7bedda162e4b"
          }
        },
        "fb7b6270613649eebe7cd2e3923272a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75ef76b0656e468bb084290dbba7061a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3a09f060095446ab1aab0f411a3714f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4982aaf88ea94b9480dd7bedda162e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db8c5593ad874757b697252ad29f21ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55fa3a04de9446bcaceb2e730a47a872",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_494b47f245314752a25a90d86706f55c",
              "IPY_MODEL_ac4f6fdd6fc54bd7ae3efc677facb70b"
            ]
          }
        },
        "55fa3a04de9446bcaceb2e730a47a872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "494b47f245314752a25a90d86706f55c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc4ac2501c334a6e845cae4bb0ccb878",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_805eae278d1a47fcba58bd1476a0c9ef"
          }
        },
        "ac4f6fdd6fc54bd7ae3efc677facb70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ac0c8db32ec4fc2a0301416d80b5a81",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 48.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c249e47fa884070bb38e7dce40506eb"
          }
        },
        "fc4ac2501c334a6e845cae4bb0ccb878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "805eae278d1a47fcba58bd1476a0c9ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ac0c8db32ec4fc2a0301416d80b5a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c249e47fa884070bb38e7dce40506eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXpKwJQ1hJLu",
        "colab_type": "text"
      },
      "source": [
        "# About the notebook\n",
        "\n",
        "The following notebook contains the Bert model with Linear layer for the classification purpose (sentiment analysis & text classification). The notebook has a following order:\n",
        "\n",
        "1. [Data Import & Preprocess](#section_1)\n",
        "2. [Tokenization & Preprocess for model](#section_2)\n",
        "3. [Fine-Tuning Function](#section_3)\n",
        "4. [Fine-Tuning](#section_4)\n",
        "5. [Confusion matrix & Critical Error](#section_5)\n",
        "6. [Train & Test](#section_6)\n",
        "\n",
        "\n",
        "The purpose of this notebook is to perform a text classification of financial news article with target value of Sentiment ($positive, neutral, negative$) and Importance ($important, normal, negligible$) regarding the firm it covers. With two parameters, our team will select 15-20 firms that are worth spotlight of a day and publish a report about the firm automatically.\n",
        "\n",
        "In this notebook, I have implemented text classification using deep learning method, and have achieved $76$% accuracy on 5-fold cv but our team focuses on what we defined as critical error.\n",
        "\n",
        "Let $S_i,r$ be the actual sentiment of the article labeled by analyst, and $S_i,p$ be the predicted sentiment of the article by the model. Then, the critical error is defined as below:\n",
        "* $Critical\\enspace Error = \\frac{\\sum_{i=1}^{n} \\mathbb{1}_\\{S_i,r = positive, S_i,p\\ = negative\\} +  \\mathbb{1}_\\{S_i,r = negative, S_i,p\\ = positive\\}}{Total\\enspace number\\enspace of\\enspace article}$\n",
        "\n",
        "The sentiment can be changed to importance with $positive = importance$ and $negative = negligible$. Since the evaluation of the article might be different by analysts' perspectives, we do not like to publish a report with news tagged as negative but some view as positive. We want such report to be published as neutral. Therefore, we care more about the critical error that we have defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlBOmtoqELlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "1a922828-963d-436e-9e86-c02e3fbd7383"
      },
      "source": [
        "#===============================================================================\n",
        "# Import Libraries and Download module necessary for the deep learning\n",
        "#===============================================================================\n",
        "\n",
        "#huggingface library installation\n",
        "!pip install transformers\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from transformers import BertForTokenClassification, AdamW, BertConfig, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import transformers\n",
        "from torch.utils.data import TensorDataset, random_split,DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import datetime\n",
        "from platform import python_version\n",
        "import sklearn\n",
        "import torch\n",
        "\n",
        "#Using Colab GPU for training\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "#To confirm that we are using GPU for the training later\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=102aac470bb65821df8966559c22b71d4ac5195ce36fe3d4c3fcae17e2e6c579\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXNu__QMDeNE",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data Import & Preprocess <a class=\"anchor\" id=\"section_1\"></a>\n",
        "\n",
        "The original news article data sets are provided by CIMS to Korea Investment. Then, the sentiments and scores of articles are labeled by the Analysts or research assistants in Research center of Korea Investment. 0,1,2 means negative, neutral, positivie respectively for the sentiment score and 0,1,2 means, negligible, normal, important respectively for the score part. \n",
        "\n",
        "The summary_v1, summary_v2 columns are the summarization by the distilbert-base-uncased summarizer uploaded in the huggingface library. summary_v1 is a summarization of text column, summary_v2 is a summarization of the summary_v1 column\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd6Bny4iCboG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "19f74f36-d987-4716-d9cf-4fb431e8d2c1"
      },
      "source": [
        "#===============================================================================\n",
        "# Load Google Drive for the data\n",
        "#===============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_direction = '/content/drive/My Drive/KIS data/CIMS_news_with_bertext_sum_full.xlsx'\n",
        "df = pd.read_excel(file_direction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apjsFTPkFQms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e1f949d9-60a9-4f66-d1f6-b7a71c4f33ad"
      },
      "source": [
        "#===============================================================================\n",
        "# Text Data & label preprocess for the model\n",
        "#===============================================================================\n",
        "\n",
        "print(len(df))\n",
        "idx_to_remove = []\n",
        "for i in range(len(df)):\n",
        "  if type(df['summary_v2'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "\n",
        "df = df.iloc[list(set(df.index) - set(idx_to_remove))]\n",
        "df.index = np.arange(0, len(df))\n",
        "print(len(df))\n",
        "\n",
        "df['importance'] = df['score']\n",
        "\n",
        "#score by daumsoft:\n",
        "#sentiment: 3 - positive, 2 - neutral, 1 - negative\n",
        "#score: 3 - important, 2 - normal, 1 - negligible \n",
        "for i in range(len(df)):\n",
        "  if df.loc[i,'sentiment'] == 3:\n",
        "    df.loc[i,'sentiment'] = 2\n",
        "  elif df.loc[i,'sentiment'] == 2:\n",
        "    df.loc[i,'sentiment'] = 1\n",
        "  elif df.loc[i,'sentiment'] == 1:\n",
        "    df.loc[i,'sentiment'] = 0\n",
        "  if df.loc[i, 'score'] == 1:\n",
        "    df.loc[i, 'importance'] = 0\n",
        "  elif df.loc[i, 'importance'] == 2:\n",
        "    df.loc[i, 'importance'] = 1\n",
        "  elif df.loc[i, 'importance'] == 3:\n",
        "    df.loc[i, 'importance'] = 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6584\n",
            "6582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpsC_GmeF5SV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "08bd9b62-d70e-4ec7-a20e-3c1325de982a"
      },
      "source": [
        "#===============================================================================\n",
        "# Prepare text data (Title + summary) for the model\n",
        "#===============================================================================\n",
        "df['title_summary'] = df['title'] + ' ' + df['summary_v2']\n",
        "title_summary_len = [len(df['title_summary'][i].split(' ')) for i in range(len(df))]\n",
        "df_stat = pd.DataFrame(title_summary_len)\n",
        "df_stat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>52.518839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.800150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>47.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>183.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  6582.000000\n",
              "mean     52.518839\n",
              "std      17.800150\n",
              "min      13.000000\n",
              "25%      42.000000\n",
              "50%      47.000000\n",
              "75%      60.000000\n",
              "max     183.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDvcDiuQGT0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f971f4c1-3a4b-440e-ff1c-69580b0dbbed"
      },
      "source": [
        "#===============================================================================\n",
        "# Data Preprocess & Distribution of labels (sentiment & importance)\n",
        "#===============================================================================\n",
        "X, y1, y2 = df['title_summary'], df['sentiment'], df['importance']\n",
        "y1_values, y2_values = y1.values, y2.values\n",
        "\n",
        "label_count_1, label_count_2 = [0,0,0], [0,0,0]\n",
        "for i in range(len(y1)):\n",
        "  label_count_1[y1_values[i]] += 1\n",
        "  label_count_2[y2_values[i]] += 1\n",
        "\n",
        "print(label_count_1, label_count_2)\n",
        "print([round(label_count_1[i]/sum(label_count_1),3) for i in range(len(label_count_1))], [round(label_count_2[i]/sum(label_count_2),3) for i in range(len(label_count_2))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1315, 3245, 2022] [2045, 2432, 2105]\n",
            "[0.2, 0.493, 0.307] [0.311, 0.369, 0.32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWpgnWXxsMxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# In order to fine-tune BERT for the importance classification\n",
        "#===============================================================================\n",
        "\n",
        "X, y1, y2 = df['title_summary'], df['importance'], df['importance']\n",
        "y1_values, y2_values = y1.values, y2.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_tNpdmBGzaN",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tokenization & Preprocess for model <a class=\"anchor\" id=\"section_2\"></a>\n",
        "\n",
        "* While the first section is for the preprocess of text data itself, this section is the preprocess for the model (BERT)\n",
        "* Convert the Text according to the model input\n",
        "* [huggingface.co](https://huggingface.co/models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqR8ngroGyUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "6b6a6ca8dfc64650ba2c95f6a8f65cce",
            "9880d182f7634adebccd143fc336b4ec",
            "bd38a78cfc1c455cb576e91f20b33654",
            "a972da2bc6d349e5a22f35af7c13af48",
            "fb7b6270613649eebe7cd2e3923272a4",
            "75ef76b0656e468bb084290dbba7061a",
            "d3a09f060095446ab1aab0f411a3714f",
            "4982aaf88ea94b9480dd7bedda162e4b"
          ]
        },
        "outputId": "acb32417-3cd4-4ef2-a6cc-949a60129317"
      },
      "source": [
        "#===============================================================================\n",
        "# Download BERT tokenizer from huggingface\n",
        "#===============================================================================\n",
        "from transformers import *\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', X[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(X[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b6a6ca8dfc64650ba2c95f6a8f65cce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Original:  Google Helping Mobile Publishing? Some Publishers Are Not So Sure In October, the software developer Alex Kras created a stir when he wrote a post titled “Google May Be Stealing Your Mobile Traffic,” in which he recounted what had happened when he used AMP on his technology blog. Joey Marburger, director of products for The Post, said that its readers were scrolling further on AMP stories, but that it was building its own fast system to gain greater control over ads and features. “\n",
            "Tokenized:  ['google', 'helping', 'mobile', 'publishing', '?', 'some', 'publishers', 'are', 'not', 'so', 'sure', 'in', 'october', ',', 'the', 'software', 'developer', 'alex', 'k', '##ras', 'created', 'a', 'stir', 'when', 'he', 'wrote', 'a', 'post', 'titled', '“', 'google', 'may', 'be', 'stealing', 'your', 'mobile', 'traffic', ',', '”', 'in', 'which', 'he', 'recounted', 'what', 'had', 'happened', 'when', 'he', 'used', 'amp', 'on', 'his', 'technology', 'blog', '.', 'joey', 'mar', '##burg', '##er', ',', 'director', 'of', 'products', 'for', 'the', 'post', ',', 'said', 'that', 'its', 'readers', 'were', 'scrolling', 'further', 'on', 'amp', 'stories', ',', 'but', 'that', 'it', 'was', 'building', 'its', 'own', 'fast', 'system', 'to', 'gain', 'greater', 'control', 'over', 'ads', 'and', 'features', '.', '“']\n",
            "Token IDs:  [8224, 5094, 4684, 4640, 1029, 2070, 8544, 2024, 2025, 2061, 2469, 1999, 2255, 1010, 1996, 4007, 9722, 4074, 1047, 8180, 2580, 1037, 16130, 2043, 2002, 2626, 1037, 2695, 4159, 1523, 8224, 2089, 2022, 11065, 2115, 4684, 4026, 1010, 1524, 1999, 2029, 2002, 22906, 2054, 2018, 3047, 2043, 2002, 2109, 23713, 2006, 2010, 2974, 9927, 1012, 9558, 9388, 4645, 2121, 1010, 2472, 1997, 3688, 2005, 1996, 2695, 1010, 2056, 2008, 2049, 8141, 2020, 28903, 2582, 2006, 23713, 3441, 1010, 2021, 2008, 2009, 2001, 2311, 2049, 2219, 3435, 2291, 2000, 5114, 3618, 2491, 2058, 14997, 1998, 2838, 1012, 1523]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxvsZFr5Hs-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "7bdf9932-8648-441b-e4a1-9e413c1db972"
      },
      "source": [
        "#===============================================================================\n",
        "# In order to decide the MAX_LEN for padding and truncation purpose, check the \n",
        "# distribution of length of text data\n",
        "#===============================================================================\n",
        "\n",
        "max_len = 0\n",
        "too_big_input = []\n",
        "len_dist = []\n",
        "for i in range(len(X)):\n",
        "  input_ids = tokenizer.encode(X[i], add_special_tokens = True)\n",
        "  max_len = max(len(input_ids), max_len)\n",
        "  len_dist.append(len(input_ids))\n",
        "  if len(input_ids) > 512:\n",
        "    too_big_input.append(i)\n",
        "\n",
        "print('Max length of title is ', max_len)\n",
        "df_stat = pd.DataFrame(len_dist)\n",
        "df_stat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of title is  222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>69.756913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>23.331647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>62.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>222.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  6582.000000\n",
              "mean     69.756913\n",
              "std      23.331647\n",
              "min      17.000000\n",
              "25%      55.000000\n",
              "50%      62.000000\n",
              "75%      80.000000\n",
              "max     222.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSsScFvpH_dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# The preprocess code for the BERT\n",
        "# The following code is from https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "#===============================================================================\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            sent,  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "            truncation = True\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV6B7cIzItcf",
        "colab_type": "text"
      },
      "source": [
        "## 3. Fine-Tuning Function <a class=\"anchor\" id=\"section_3\"></a>\n",
        "\n",
        "* Declare Model and train functions\n",
        "* All the other notebooks follow the same procedure except this section.\n",
        "* Most of the implication of the model is from this [website](https://mccormickml.com/2019/07/22/BERT-fine-tuning/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfvqkPi3ImjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a6b650c0-6aee-4515-d18f-46f4ef5e3672"
      },
      "source": [
        "#===============================================================================\n",
        "# Declare the BERT Classifier for later train and test purpose\n",
        "# if one wants to change the model, one can modify the below section\n",
        "#===============================================================================\n",
        "\n",
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False, layers_to_freeze = []):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 100, 3\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "          if layers_to_freeze != []:\n",
        "            for i in layers_to_freeze:\n",
        "              for param in self.bert.encoder.layer[i].parameters():\n",
        "                param.requires_grad = False\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 43 µs, sys: 0 ns, total: 43 µs\n",
            "Wall time: 45.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrNOvQ8yJFx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Initialize model for the later train purpose\n",
        "#===============================================================================\n",
        "\n",
        "def initialize_model(epochs=4, layers_to_freeze = []):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False, layers_to_freeze = layers_to_freeze)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=2e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNWOTD5yJtKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Train & Evaluate function \n",
        "#===============================================================================\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    #return float(val_loss), float(val_accuracy)\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0bd3iqhKD1v",
        "colab_type": "text"
      },
      "source": [
        "## 4. Fine-Tuning <a class=\"anchor\" id=\"section_4\"></a>\n",
        "\n",
        "\n",
        "* Actual fine-tuning process. I have used 5-fold cv to check the overfitting. \n",
        "* If one wants to train once, please put $break$ at the end of the line.\n",
        "\n",
        "\n",
        "According to the [Devlin et al., 2018](https://arxiv.org/abs/1810.04805), the following parameters' range works well across all task.\n",
        "* Batch size: 16, 32\n",
        "* Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "* Number of epochs: 2,3,4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CxZouwIJ-PU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967,
          "referenced_widgets": [
            "db8c5593ad874757b697252ad29f21ad",
            "55fa3a04de9446bcaceb2e730a47a872",
            "494b47f245314752a25a90d86706f55c",
            "ac4f6fdd6fc54bd7ae3efc677facb70b",
            "fc4ac2501c334a6e845cae4bb0ccb878",
            "805eae278d1a47fcba58bd1476a0c9ef",
            "1ac0c8db32ec4fc2a0301416d80b5a81",
            "4c249e47fa884070bb38e7dce40506eb"
          ]
        },
        "outputId": "5d9f8c04-c15b-4cbe-8d26-36ac2a2fe646"
      },
      "source": [
        "#===============================================================================\n",
        "# Part where we train using the 5-fold cv\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "#train and val are indices\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 42)\n",
        "\n",
        "batch_size = 16\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "\n",
        "y1 = y1.astype(int)\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "  #Data Preparation\n",
        "  X_train = X[train_index]\n",
        "  X_val = X[val_index]\n",
        "  y1_train = y1[train_index]\n",
        "  y1_val = y1[val_index]\n",
        "  \n",
        "  train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "  val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
        "  train_labels = torch.tensor(y1_train.values)\n",
        "  val_labels = torch.tensor(y1_val.values)\n",
        "  \n",
        "  #Data Loader Class\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "  val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "  val_sampler = RandomSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n",
        "\n",
        "  #Fine Tune and Evaluation\n",
        "  set_seed(42)    # Set seed for reproducibility\n",
        "  #epoch 수 조정을 통해 나은 결과가 나올 수 있습니다.\n",
        "  bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "  # evaluation false라고 하면 bert_classfier는 훈련만 진행합니다.\n",
        "  # 다른 노트북에서 훈련 후 예측하는 과정을 확인 할 수 있습니다.\n",
        "  val_loss1, val_accuracy1 = train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)\n",
        "  \n",
        "  val_loss.append(val_loss1)\n",
        "  val_accuracy.append(val_accuracy1)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db8c5593ad874757b697252ad29f21ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.986993   |     -      |     -     |   15.34  \n",
            "   1    |   40    |   0.969681   |     -      |     -     |   14.27  \n",
            "   1    |   60    |   0.912512   |     -      |     -     |   14.24  \n",
            "   1    |   80    |   0.905262   |     -      |     -     |   14.22  \n",
            "   1    |   100   |   0.885821   |     -      |     -     |   14.21  \n",
            "   1    |   120   |   0.934805   |     -      |     -     |   14.21  \n",
            "   1    |   140   |   0.868877   |     -      |     -     |   14.20  \n",
            "   1    |   160   |   0.833068   |     -      |     -     |   14.21  \n",
            "   1    |   180   |   0.843923   |     -      |     -     |   14.20  \n",
            "   1    |   200   |   0.801833   |     -      |     -     |   14.17  \n",
            "   1    |   220   |   0.747846   |     -      |     -     |   14.23  \n",
            "   1    |   240   |   0.767086   |     -      |     -     |   14.20  \n",
            "   1    |   260   |   0.801684   |     -      |     -     |   14.18  \n",
            "   1    |   280   |   0.880151   |     -      |     -     |   14.19  \n",
            "   1    |   300   |   0.890611   |     -      |     -     |   14.17  \n",
            "   1    |   320   |   0.782125   |     -      |     -     |   14.18  \n",
            "   1    |   329   |   0.884836   |     -      |     -     |   5.84   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.864230   |  0.774145  |   64.05   |  253.58  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.695397   |     -      |     -     |   14.85  \n",
            "   2    |   40    |   0.678846   |     -      |     -     |   14.18  \n",
            "   2    |   60    |   0.675754   |     -      |     -     |   14.18  \n",
            "   2    |   80    |   0.591792   |     -      |     -     |   14.16  \n",
            "   2    |   100   |   0.680386   |     -      |     -     |   14.19  \n",
            "   2    |   120   |   0.597595   |     -      |     -     |   14.19  \n",
            "   2    |   140   |   0.678661   |     -      |     -     |   14.20  \n",
            "   2    |   160   |   0.726575   |     -      |     -     |   14.20  \n",
            "   2    |   180   |   0.711978   |     -      |     -     |   14.21  \n",
            "   2    |   200   |   0.631480   |     -      |     -     |   14.19  \n",
            "   2    |   220   |   0.695111   |     -      |     -     |   14.19  \n",
            "   2    |   240   |   0.658816   |     -      |     -     |   14.18  \n",
            "   2    |   260   |   0.709796   |     -      |     -     |   14.22  \n",
            "   2    |   280   |   0.640762   |     -      |     -     |   14.17  \n",
            "   2    |   300   |   0.596989   |     -      |     -     |   14.22  \n",
            "   2    |   320   |   0.701570   |     -      |     -     |   14.19  \n",
            "   2    |   329   |   0.571848   |     -      |     -     |   5.81   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.664461   |  0.784928  |   64.17   |  252.91  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pALRTHtQKfhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f28a4f86-0625-4dae-b7d9-a0b4f9cbd566"
      },
      "source": [
        "#===============================================================================\n",
        "# Print the mean loss and accuracy of the 5-fold cv\n",
        "#===============================================================================\n",
        "print('The mean validation accuracy of 5-fold cv is: ',np.mean(val_accuracy))\n",
        "print('The mean validation loss of 5-fold cv is: ', np.mean(val_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean validation accuracy of 5-fold cv is:  64.17168674698796\n",
            "The mean validation loss of 5-fold cv is:  0.7849277178925204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFV-njv7LDCQ",
        "colab_type": "text"
      },
      "source": [
        "## 5. Confusion matrix & Critical Error <a class=\"anchor\" id=\"section_5\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGcBqXEILbzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Prediction function given the fine-tuned model\n",
        "#===============================================================================\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    val_accuracy = []\n",
        "    all_pred = []\n",
        "    all_real = []\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "        all_real.append(b_labels)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        all_pred.append(preds)\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    all_real = torch.cat(all_real)\n",
        "    all_pred = torch.cat(all_pred)\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    #val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_accuracy,all_real, all_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHgcqTnvMc0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Import py file for confusion matrtix\n",
        "#===============================================================================\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from confusion_matrix import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-xjHuoMMm59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3ea74ec3-ab60-4257-dd2e-29c4fea17fc5"
      },
      "source": [
        "#===============================================================================\n",
        "# Make prediction for confusion matrix and critical error\n",
        "#===============================================================================\n",
        "acc,all_real, all_pred = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "critical_error = 0\n",
        "crit_error_index = []\n",
        "hit = 0\n",
        "for i in range(len(all_real)):\n",
        "  if all_real[i] == all_pred[i]:\n",
        "    hit += 1\n",
        "  if abs(all_pred[i] - all_real[i]) == 2:\n",
        "    critical_error += 1\n",
        "    crit_error_index.append(i)\n",
        "\n",
        "all_pred = all_pred.cpu().numpy()\n",
        "all_real = all_real.cpu().numpy()\n",
        "\n",
        "print('The accuracy of the model is :', hit/len(all_real))\n",
        "print('The critical error is : ',critical_error/len(all_real))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model is : 0.6454062262718299\n",
            "The critical error is :  0.04176157934700076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkk0fcDNMp5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "72ee19af-de86-4c41-af6c-a75f95a39406"
      },
      "source": [
        "#===============================================================================\n",
        "# Visualization of Confusion matrix\n",
        "#===============================================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_real, all_pred)\n",
        "plot_confusion_matrix(cm,\n",
        "                      ['neg','neu', 'pos'],\n",
        "                      title='Confusion matrix',\n",
        "                      cmap=None,\n",
        "                      normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cmEbba2g9YG",
        "colab_type": "text"
      },
      "source": [
        "## Train & Test <a class=\"anchor\" id=\"section_6\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFh5PSSqg81H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "805af02a-5150-4a03-93f9-e584827b24c5"
      },
      "source": [
        "#===============================================================================\n",
        "# import py for the EDA (Easy data Augmentation)\n",
        "# original code from https://github.com/jasonwei20/eda_nlp\n",
        "#===============================================================================\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from easy_data_augmentation import *\n",
        "from confusion_matrix import *\n",
        "\n",
        "X, y1 = gen_eda(X, y1, alpha = 0.2, num_aug = 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTPXjWcJgljI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c3b43be-a3de-474b-822c-a845415fce41"
      },
      "source": [
        "#===============================================================================\n",
        "# Train for prediction\n",
        "#===============================================================================\n",
        "\n",
        "batch_size = 64\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "layers_to_freeze = [0,1,2,3,4,5,6,7]\n",
        "\n",
        "\n",
        "train_inputs, train_masks = preprocessing_for_bert(X)\n",
        "train_labels = torch.tensor(y1)\n",
        "#Data Loader Class\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=4, layers_to_freeze = layers_to_freeze)\n",
        "train(bert_classifier, train_dataloader, epochs=4, evaluation=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.087327   |     -      |     -     |   11.79  \n",
            "   1    |   40    |   1.046919   |     -      |     -     |   11.22  \n",
            "   1    |   60    |   1.022933   |     -      |     -     |   11.21  \n",
            "   1    |   80    |   0.980157   |     -      |     -     |   11.22  \n",
            "   1    |   100   |   0.971398   |     -      |     -     |   11.23  \n",
            "   1    |   120   |   0.948139   |     -      |     -     |   11.22  \n",
            "   1    |   140   |   0.930331   |     -      |     -     |   11.22  \n",
            "   1    |   160   |   0.947995   |     -      |     -     |   11.22  \n",
            "   1    |   180   |   0.906548   |     -      |     -     |   11.23  \n",
            "   1    |   200   |   0.914452   |     -      |     -     |   11.24  \n",
            "   1    |   220   |   0.880794   |     -      |     -     |   11.23  \n",
            "   1    |   240   |   0.879363   |     -      |     -     |   11.23  \n",
            "   1    |   260   |   0.860546   |     -      |     -     |   11.23  \n",
            "   1    |   280   |   0.865329   |     -      |     -     |   11.22  \n",
            "   1    |   300   |   0.872614   |     -      |     -     |   11.23  \n",
            "   1    |   320   |   0.862202   |     -      |     -     |   11.21  \n",
            "   1    |   340   |   0.835688   |     -      |     -     |   11.22  \n",
            "   1    |   360   |   0.827965   |     -      |     -     |   11.25  \n",
            "   1    |   380   |   0.817923   |     -      |     -     |   11.22  \n",
            "   1    |   400   |   0.815584   |     -      |     -     |   11.23  \n",
            "   1    |   420   |   0.826763   |     -      |     -     |   11.23  \n",
            "   1    |   440   |   0.842218   |     -      |     -     |   11.22  \n",
            "   1    |   460   |   0.825917   |     -      |     -     |   11.22  \n",
            "   1    |   480   |   0.784178   |     -      |     -     |   11.21  \n",
            "   1    |   500   |   0.783383   |     -      |     -     |   11.23  \n",
            "   1    |   520   |   0.786392   |     -      |     -     |   11.24  \n",
            "   1    |   540   |   0.784108   |     -      |     -     |   11.24  \n",
            "   1    |   560   |   0.783854   |     -      |     -     |   11.23  \n",
            "   1    |   580   |   0.772723   |     -      |     -     |   11.23  \n",
            "   1    |   600   |   0.781181   |     -      |     -     |   11.23  \n",
            "   1    |   620   |   0.767241   |     -      |     -     |   11.21  \n",
            "   1    |   640   |   0.770157   |     -      |     -     |   11.22  \n",
            "   1    |   660   |   0.788806   |     -      |     -     |   11.23  \n",
            "   1    |   680   |   0.776303   |     -      |     -     |   11.22  \n",
            "   1    |   700   |   0.783979   |     -      |     -     |   11.23  \n",
            "   1    |   719   |   0.730636   |     -      |     -     |   10.63  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.710855   |     -      |     -     |   11.81  \n",
            "   2    |   40    |   0.710460   |     -      |     -     |   11.23  \n",
            "   2    |   60    |   0.690351   |     -      |     -     |   11.22  \n",
            "   2    |   80    |   0.703891   |     -      |     -     |   11.22  \n",
            "   2    |   100   |   0.699458   |     -      |     -     |   11.22  \n",
            "   2    |   120   |   0.724051   |     -      |     -     |   11.23  \n",
            "   2    |   140   |   0.665647   |     -      |     -     |   11.21  \n",
            "   2    |   160   |   0.717316   |     -      |     -     |   11.22  \n",
            "   2    |   180   |   0.703147   |     -      |     -     |   11.22  \n",
            "   2    |   200   |   0.674699   |     -      |     -     |   11.22  \n",
            "   2    |   220   |   0.706215   |     -      |     -     |   11.21  \n",
            "   2    |   240   |   0.651479   |     -      |     -     |   11.23  \n",
            "   2    |   260   |   0.667202   |     -      |     -     |   11.22  \n",
            "   2    |   280   |   0.641732   |     -      |     -     |   11.22  \n",
            "   2    |   300   |   0.676884   |     -      |     -     |   11.23  \n",
            "   2    |   320   |   0.635687   |     -      |     -     |   11.22  \n",
            "   2    |   340   |   0.660883   |     -      |     -     |   11.22  \n",
            "   2    |   360   |   0.633829   |     -      |     -     |   11.23  \n",
            "   2    |   380   |   0.612127   |     -      |     -     |   11.25  \n",
            "   2    |   400   |   0.625514   |     -      |     -     |   11.23  \n",
            "   2    |   420   |   0.647740   |     -      |     -     |   11.22  \n",
            "   2    |   440   |   0.645751   |     -      |     -     |   11.23  \n",
            "   2    |   460   |   0.675953   |     -      |     -     |   11.23  \n",
            "   2    |   480   |   0.622895   |     -      |     -     |   11.22  \n",
            "   2    |   500   |   0.646030   |     -      |     -     |   11.22  \n",
            "   2    |   520   |   0.639179   |     -      |     -     |   11.22  \n",
            "   2    |   540   |   0.637059   |     -      |     -     |   11.24  \n",
            "   2    |   560   |   0.609876   |     -      |     -     |   11.23  \n",
            "   2    |   580   |   0.610499   |     -      |     -     |   11.22  \n",
            "   2    |   600   |   0.592714   |     -      |     -     |   11.22  \n",
            "   2    |   620   |   0.597906   |     -      |     -     |   11.23  \n",
            "   2    |   640   |   0.602766   |     -      |     -     |   11.23  \n",
            "   2    |   660   |   0.597434   |     -      |     -     |   11.23  \n",
            "   2    |   680   |   0.592676   |     -      |     -     |   11.21  \n",
            "   2    |   700   |   0.574272   |     -      |     -     |   11.24  \n",
            "   2    |   719   |   0.578611   |     -      |     -     |   10.62  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.574988   |     -      |     -     |   11.79  \n",
            "   3    |   40    |   0.540946   |     -      |     -     |   11.22  \n",
            "   3    |   60    |   0.540521   |     -      |     -     |   11.23  \n",
            "   3    |   80    |   0.542110   |     -      |     -     |   11.22  \n",
            "   3    |   100   |   0.518418   |     -      |     -     |   11.23  \n",
            "   3    |   120   |   0.534643   |     -      |     -     |   11.23  \n",
            "   3    |   140   |   0.528528   |     -      |     -     |   11.22  \n",
            "   3    |   160   |   0.528428   |     -      |     -     |   11.23  \n",
            "   3    |   180   |   0.533192   |     -      |     -     |   11.23  \n",
            "   3    |   200   |   0.522695   |     -      |     -     |   11.22  \n",
            "   3    |   220   |   0.526960   |     -      |     -     |   11.23  \n",
            "   3    |   240   |   0.489031   |     -      |     -     |   11.22  \n",
            "   3    |   260   |   0.505197   |     -      |     -     |   11.22  \n",
            "   3    |   280   |   0.538621   |     -      |     -     |   11.24  \n",
            "   3    |   300   |   0.467756   |     -      |     -     |   11.23  \n",
            "   3    |   320   |   0.511502   |     -      |     -     |   11.23  \n",
            "   3    |   340   |   0.514000   |     -      |     -     |   11.22  \n",
            "   3    |   360   |   0.494071   |     -      |     -     |   11.24  \n",
            "   3    |   380   |   0.515893   |     -      |     -     |   11.23  \n",
            "   3    |   400   |   0.509615   |     -      |     -     |   11.21  \n",
            "   3    |   420   |   0.479668   |     -      |     -     |   11.21  \n",
            "   3    |   440   |   0.485277   |     -      |     -     |   11.23  \n",
            "   3    |   460   |   0.488831   |     -      |     -     |   11.22  \n",
            "   3    |   480   |   0.472777   |     -      |     -     |   11.22  \n",
            "   3    |   500   |   0.491969   |     -      |     -     |   11.23  \n",
            "   3    |   520   |   0.489069   |     -      |     -     |   11.22  \n",
            "   3    |   540   |   0.481124   |     -      |     -     |   11.23  \n",
            "   3    |   560   |   0.475659   |     -      |     -     |   11.26  \n",
            "   3    |   580   |   0.462222   |     -      |     -     |   11.23  \n",
            "   3    |   600   |   0.456306   |     -      |     -     |   11.23  \n",
            "   3    |   620   |   0.453514   |     -      |     -     |   11.22  \n",
            "   3    |   640   |   0.451141   |     -      |     -     |   11.24  \n",
            "   3    |   660   |   0.454364   |     -      |     -     |   11.23  \n",
            "   3    |   680   |   0.445546   |     -      |     -     |   11.23  \n",
            "   3    |   700   |   0.454636   |     -      |     -     |   11.22  \n",
            "   3    |   719   |   0.451403   |     -      |     -     |   10.63  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.407340   |     -      |     -     |   11.79  \n",
            "   4    |   40    |   0.451403   |     -      |     -     |   11.22  \n",
            "   4    |   60    |   0.443474   |     -      |     -     |   11.23  \n",
            "   4    |   80    |   0.410318   |     -      |     -     |   11.22  \n",
            "   4    |   100   |   0.416117   |     -      |     -     |   11.23  \n",
            "   4    |   120   |   0.444624   |     -      |     -     |   11.22  \n",
            "   4    |   140   |   0.418113   |     -      |     -     |   11.22  \n",
            "   4    |   160   |   0.429820   |     -      |     -     |   11.23  \n",
            "   4    |   180   |   0.447706   |     -      |     -     |   11.24  \n",
            "   4    |   200   |   0.432104   |     -      |     -     |   11.23  \n",
            "   4    |   220   |   0.419420   |     -      |     -     |   11.24  \n",
            "   4    |   240   |   0.400356   |     -      |     -     |   11.24  \n",
            "   4    |   260   |   0.398065   |     -      |     -     |   11.22  \n",
            "   4    |   280   |   0.448750   |     -      |     -     |   11.23  \n",
            "   4    |   300   |   0.386706   |     -      |     -     |   11.23  \n",
            "   4    |   320   |   0.382748   |     -      |     -     |   11.24  \n",
            "   4    |   340   |   0.421252   |     -      |     -     |   11.22  \n",
            "   4    |   360   |   0.423461   |     -      |     -     |   11.22  \n",
            "   4    |   380   |   0.401934   |     -      |     -     |   11.23  \n",
            "   4    |   400   |   0.398722   |     -      |     -     |   11.23  \n",
            "   4    |   420   |   0.393930   |     -      |     -     |   11.22  \n",
            "   4    |   440   |   0.401219   |     -      |     -     |   11.23  \n",
            "   4    |   460   |   0.406609   |     -      |     -     |   11.23  \n",
            "   4    |   480   |   0.416457   |     -      |     -     |   11.22  \n",
            "   4    |   500   |   0.420948   |     -      |     -     |   11.22  \n",
            "   4    |   520   |   0.396372   |     -      |     -     |   11.24  \n",
            "   4    |   540   |   0.370318   |     -      |     -     |   11.22  \n",
            "   4    |   560   |   0.379749   |     -      |     -     |   11.23  \n",
            "   4    |   580   |   0.361549   |     -      |     -     |   11.23  \n",
            "   4    |   600   |   0.370177   |     -      |     -     |   11.24  \n",
            "   4    |   620   |   0.406659   |     -      |     -     |   11.23  \n",
            "   4    |   640   |   0.401221   |     -      |     -     |   11.23  \n",
            "   4    |   660   |   0.391688   |     -      |     -     |   11.23  \n",
            "   4    |   680   |   0.398598   |     -      |     -     |   11.23  \n",
            "   4    |   700   |   0.389090   |     -      |     -     |   11.21  \n",
            "   4    |   719   |   0.420281   |     -      |     -     |   10.62  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfB35PR5gnoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "885892d7-2120-41c3-f105-6b8d787583d9"
      },
      "source": [
        "#===============================================================================\n",
        "# Test the trained model\n",
        "#===============================================================================\n",
        "\n",
        "df_test = pd.read_json('/content/drive/My Drive/KIS data/test_data.json')\n",
        "\n",
        "print(len(df_test))\n",
        "idx_to_remove = []\n",
        "for i in range(len(df_test)):\n",
        "  if type(df_test['summary'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "  if type(df_test['title'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "\n",
        "df_test = df_test.iloc[list(set(df_test.index) - set(idx_to_remove))]\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "print(len(df_test))\n",
        "\n",
        "\n",
        "\n",
        "df_test['title_summary'] = df_test['title'] + ' ' + df_test['summary']\n",
        "df_test= df_test.drop(df_test[df_test['title_summary'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "df_test= df_test.drop(df_test[df_test['importance'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "df_test= df_test.drop(df_test[df_test['sentiment'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "title_summary_len = [len(df_test['title_summary'][i].split(' ')) for i in range(len(df_test))]\n",
        "df_stat = pd.DataFrame(title_summary_len)\n",
        "df_stat.describe()\n",
        "\n",
        "\n",
        "X_test, y1_test, y2_test = df_test['title_summary'], df_test['sentiment'].apply(int), df_test['importance'].apply(int)\n",
        "y1_test_values, y2_test_values = y1_test.values, y2_test.values\n",
        "\n",
        "label_count_test_1, label_count_test_2 = [0,0,0], [0,0,0]\n",
        "for i in range(len(y1_test)):\n",
        "  label_count_test_1[y1_test_values[i]] += 1\n",
        "  label_count_test_2[y2_test_values[i]] += 1\n",
        "\n",
        "print(label_count_test_1, label_count_test_2)\n",
        "print([round(label_count_test_1[i]/sum(label_count_test_1),3) for i in range(len(label_count_test_1))], [round(label_count_test_2[i]/sum(label_count_test_2),3) for i in range(len(label_count_test_2))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2898\n",
            "2898\n",
            "[366, 1585, 915] [1052, 918, 896]\n",
            "[0.128, 0.553, 0.319] [0.367, 0.32, 0.313]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnncpEUaheWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3d5cb7e4-4bc1-4c4d-e9df-7d7226193f43"
      },
      "source": [
        "#===============================================================================\n",
        "# Make prediction on test data\n",
        "#===============================================================================\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "test_labels = torch.tensor(y1_test)\n",
        "#Data Loader Class\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)\n",
        "\n",
        "acc,all_real, all_pred = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "critical_error = 0\n",
        "crit_error_index = []\n",
        "hit = 0\n",
        "for i in range(len(all_real)):\n",
        "  if all_real[i] == all_pred[i]:\n",
        "    hit += 1\n",
        "  if abs(all_pred[i] - all_real[i]) == 2:\n",
        "    critical_error += 1\n",
        "    crit_error_index.append(i)\n",
        "\n",
        "all_pred = all_pred.cpu().numpy()\n",
        "all_real = all_real.cpu().numpy()\n",
        "\n",
        "print('The accuracy of the model is :', hit/len(all_real))\n",
        "print('The critical error is : ',critical_error/len(all_real))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model is : 0.31751570132588974\n",
            "The critical error is :  0.15247732030704816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIFOf8XThtCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Visualization of confusion matrix\n",
        "#===============================================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_real, all_pred)\n",
        "plot_confusion_matrix(cm,\n",
        "                      ['neg','neu', 'pos'],\n",
        "                      title='Confusion matrix',\n",
        "                      cmap=None,\n",
        "                      normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}