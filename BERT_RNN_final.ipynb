{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_RNN_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38302afc8c4c4a57b0ef9dabb77bf61c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ec2d857cace4d1da8409e005f70dc8c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_59fb25093598460a890ee8b052b47203",
              "IPY_MODEL_cb8ad75db0d9441dbb802144406e0169"
            ]
          }
        },
        "4ec2d857cace4d1da8409e005f70dc8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59fb25093598460a890ee8b052b47203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7aa7dc08a4041cd85ce992c218209c2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2acc6224a55343bebd1f02a33ad12171"
          }
        },
        "cb8ad75db0d9441dbb802144406e0169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_790879cae18d41bba447fb8ec8bdc4eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 302kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1b1a78c592e47b588f9f8577f3ac3d0"
          }
        },
        "e7aa7dc08a4041cd85ce992c218209c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2acc6224a55343bebd1f02a33ad12171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "790879cae18d41bba447fb8ec8bdc4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1b1a78c592e47b588f9f8577f3ac3d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b245686d4e24ab6ae1f39dbbbb7da2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3252f65d5a5c414986083ff0cc3e0a1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_247f88f6ce5d4e0384253952e1550e10",
              "IPY_MODEL_79395deaa6d4413ea9ed11644a33c527"
            ]
          }
        },
        "3252f65d5a5c414986083ff0cc3e0a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "247f88f6ce5d4e0384253952e1550e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03016e37f9ae401f9335328dfbacad41",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b86262084d4a4b42a101235032e44be3"
          }
        },
        "79395deaa6d4413ea9ed11644a33c527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a68db96dadd241609adbdab8ff1f9e58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.54kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0572612babe84e418059936ba40d2ce7"
          }
        },
        "03016e37f9ae401f9335328dfbacad41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b86262084d4a4b42a101235032e44be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a68db96dadd241609adbdab8ff1f9e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0572612babe84e418059936ba40d2ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "975d9dcea1c2420c9cfb2fbf0506ceaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a4fbc013ef04c2d88996d00ec2c6d33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_abf271a19ca24f62b7740bed4488263c",
              "IPY_MODEL_0238d82437f04e8cb42fb29d42c3fb9e"
            ]
          }
        },
        "5a4fbc013ef04c2d88996d00ec2c6d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abf271a19ca24f62b7740bed4488263c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8315c8feea204ad4a8dd4676675fda49",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_468bbf290fbc49a499ecc173d70dd5eb"
          }
        },
        "0238d82437f04e8cb42fb29d42c3fb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2fbc2788be648b88a1a2a7cac245a5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:17&lt;00:00, 25.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d32935b757b14d0e93177e10e30e0b06"
          }
        },
        "8315c8feea204ad4a8dd4676675fda49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "468bbf290fbc49a499ecc173d70dd5eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2fbc2788be648b88a1a2a7cac245a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d32935b757b14d0e93177e10e30e0b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFi0rvtcpiHT",
        "colab_type": "text"
      },
      "source": [
        "# About the notebook\n",
        "\n",
        "The following notebook contains the Bert model with Recurrent Neural Network for the classification purpose (sentiment analysis & text classification). The notebook has a following order:\n",
        "\n",
        "1. [Data Import & Preprocess](#section_1)\n",
        "2. [Tokenization & Preprocess for model](#section_2)\n",
        "3. [Fine-Tuning Function](#section_3)\n",
        "4. [Fine-Tuning](#section_4)\n",
        "5. [Confusion matrix & Critical Error](#section_5)\n",
        "6. [Train & Test](#section_6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Brsk352koqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "de6f0d9f-d491-4875-92c5-8b61dbf892b4"
      },
      "source": [
        "#===============================================================================\n",
        "# Import Libraries and Download module necessary for the deep learning\n",
        "#===============================================================================\n",
        "\n",
        "#huggingface library installation\n",
        "!pip install transformers\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from transformers import BertForTokenClassification, AdamW, BertConfig, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import transformers\n",
        "from torch.utils.data import TensorDataset, random_split,DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import datetime\n",
        "from platform import python_version\n",
        "import sklearn\n",
        "import torch\n",
        "\n",
        "#Using Colab GPU for training\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "#To confirm that we are using GPU for the training later\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31kB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 16.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=fe9d994634a5a6f78e50a32c61aef6a84526f6e7c64d440cddfb9e86efa64655\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxh_ZZ3RlHzp",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data Import & Preprocess <a class=\"anchor\" id=\"section_1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnsmESLFkpth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "e80e0ca2-2ed5-4cfc-f209-1365ceaa193c"
      },
      "source": [
        "#===============================================================================\n",
        "# Load Google Drive for the data\n",
        "#===============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_direction = '/content/drive/My Drive/KIS data/CIMS_news_with_bertext_sum_full.xlsx'\n",
        "df = pd.read_excel(file_direction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdOJjPqglJHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1ba71a6a-917e-4738-a97f-e2c11ef13866"
      },
      "source": [
        "#===============================================================================\n",
        "# Text Data & label preprocess for the model\n",
        "#===============================================================================\n",
        "\n",
        "print(len(df))\n",
        "idx_to_remove = []\n",
        "for i in range(len(df)):\n",
        "  if type(df['summary_v2'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "\n",
        "df = df.iloc[list(set(df.index) - set(idx_to_remove))]\n",
        "df.index = np.arange(0, len(df))\n",
        "print(len(df))\n",
        "\n",
        "df['importance'] = df['score']\n",
        "\n",
        "#score by daumsoft:\n",
        "#sentiment: 3 - positive, 2 - neutral, 1 - negative\n",
        "#score: 3 - important, 2 - normal, 1 - negligible \n",
        "for i in range(len(df)):\n",
        "  if df.loc[i,'sentiment'] == 3:\n",
        "    df.loc[i,'sentiment'] = 2\n",
        "  elif df.loc[i,'sentiment'] == 2:\n",
        "    df.loc[i,'sentiment'] = 1\n",
        "  elif df.loc[i,'sentiment'] == 1:\n",
        "    df.loc[i,'sentiment'] = 0\n",
        "  if df.loc[i, 'score'] == 1:\n",
        "    df.loc[i, 'importance'] = 0\n",
        "  elif df.loc[i, 'importance'] == 2:\n",
        "    df.loc[i, 'importance'] = 1\n",
        "  elif df.loc[i, 'importance'] == 3:\n",
        "    df.loc[i, 'importance'] = 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6584\n",
            "6582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwoBleoHlOvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d23138dc-67ed-47f1-c110-a119173bddec"
      },
      "source": [
        "#===============================================================================\n",
        "# Prepare text data (Title + summary) for the model\n",
        "#===============================================================================\n",
        "df['title_summary'] = df['title'] + ' ' + df['summary_v2']\n",
        "title_summary_len = [len(df['title_summary'][i].split(' ')) for i in range(len(df))]\n",
        "df_stat = pd.DataFrame(title_summary_len)\n",
        "df_stat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>52.518839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.800150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>47.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>183.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  6582.000000\n",
              "mean     52.518839\n",
              "std      17.800150\n",
              "min      13.000000\n",
              "25%      42.000000\n",
              "50%      47.000000\n",
              "75%      60.000000\n",
              "max     183.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKYzfSC6lPnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "758cc197-9399-440a-a3fc-29b1098a091c"
      },
      "source": [
        "#===============================================================================\n",
        "# Data Preprocess & Distribution of labels (sentiment & importance)\n",
        "#===============================================================================\n",
        "X, y1, y2 = df['title_summary'], df['sentiment'], df['importance']\n",
        "y1_values, y2_values = y1.values, y2.values\n",
        "\n",
        "label_count_1, label_count_2 = [0,0,0], [0,0,0]\n",
        "for i in range(len(y1)):\n",
        "  label_count_1[y1_values[i]] += 1\n",
        "  label_count_2[y2_values[i]] += 1\n",
        "\n",
        "print(label_count_1, label_count_2)\n",
        "print([round(label_count_1[i]/sum(label_count_1),3) for i in range(len(label_count_1))], [round(label_count_2[i]/sum(label_count_2),3) for i in range(len(label_count_2))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1315, 3245, 2022] [2045, 2432, 2105]\n",
            "[0.2, 0.493, 0.307] [0.311, 0.369, 0.32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjDIeBgjsiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# In order to fine-tune BERT for the importance classification\n",
        "#===============================================================================\n",
        "X, y1, y2 = df['title_summary'], df['importance'], df['importance']\n",
        "y1_values, y2_values = y1.values, y2.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScM79szClRUx",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tokenization & Preprocess for model <a class=\"anchor\" id=\"section_2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0mhwZ2ClQUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "38302afc8c4c4a57b0ef9dabb77bf61c",
            "4ec2d857cace4d1da8409e005f70dc8c",
            "59fb25093598460a890ee8b052b47203",
            "cb8ad75db0d9441dbb802144406e0169",
            "e7aa7dc08a4041cd85ce992c218209c2",
            "2acc6224a55343bebd1f02a33ad12171",
            "790879cae18d41bba447fb8ec8bdc4eb",
            "c1b1a78c592e47b588f9f8577f3ac3d0"
          ]
        },
        "outputId": "69ae7475-2e25-4531-acd4-6023280c1cb6"
      },
      "source": [
        "#===============================================================================\n",
        "# Download BERT tokenizer from huggingface\n",
        "#===============================================================================\n",
        "from transformers import *\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', X[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(X[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38302afc8c4c4a57b0ef9dabb77bf61c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Original:  Google Helping Mobile Publishing? Some Publishers Are Not So Sure In October, the software developer Alex Kras created a stir when he wrote a post titled “Google May Be Stealing Your Mobile Traffic,” in which he recounted what had happened when he used AMP on his technology blog. Joey Marburger, director of products for The Post, said that its readers were scrolling further on AMP stories, but that it was building its own fast system to gain greater control over ads and features. “\n",
            "Tokenized:  ['google', 'helping', 'mobile', 'publishing', '?', 'some', 'publishers', 'are', 'not', 'so', 'sure', 'in', 'october', ',', 'the', 'software', 'developer', 'alex', 'k', '##ras', 'created', 'a', 'stir', 'when', 'he', 'wrote', 'a', 'post', 'titled', '“', 'google', 'may', 'be', 'stealing', 'your', 'mobile', 'traffic', ',', '”', 'in', 'which', 'he', 'recounted', 'what', 'had', 'happened', 'when', 'he', 'used', 'amp', 'on', 'his', 'technology', 'blog', '.', 'joey', 'mar', '##burg', '##er', ',', 'director', 'of', 'products', 'for', 'the', 'post', ',', 'said', 'that', 'its', 'readers', 'were', 'scrolling', 'further', 'on', 'amp', 'stories', ',', 'but', 'that', 'it', 'was', 'building', 'its', 'own', 'fast', 'system', 'to', 'gain', 'greater', 'control', 'over', 'ads', 'and', 'features', '.', '“']\n",
            "Token IDs:  [8224, 5094, 4684, 4640, 1029, 2070, 8544, 2024, 2025, 2061, 2469, 1999, 2255, 1010, 1996, 4007, 9722, 4074, 1047, 8180, 2580, 1037, 16130, 2043, 2002, 2626, 1037, 2695, 4159, 1523, 8224, 2089, 2022, 11065, 2115, 4684, 4026, 1010, 1524, 1999, 2029, 2002, 22906, 2054, 2018, 3047, 2043, 2002, 2109, 23713, 2006, 2010, 2974, 9927, 1012, 9558, 9388, 4645, 2121, 1010, 2472, 1997, 3688, 2005, 1996, 2695, 1010, 2056, 2008, 2049, 8141, 2020, 28903, 2582, 2006, 23713, 3441, 1010, 2021, 2008, 2009, 2001, 2311, 2049, 2219, 3435, 2291, 2000, 5114, 3618, 2491, 2058, 14997, 1998, 2838, 1012, 1523]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJYFy9hslSUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "5ee7df4b-f6f4-402f-d72e-a437fa2c260f"
      },
      "source": [
        "#===============================================================================\n",
        "# In order to decide the MAX_LEN for padding and truncation purpose, check the \n",
        "# distribution of length of text data\n",
        "#===============================================================================\n",
        "\n",
        "max_len = 0\n",
        "too_big_input = []\n",
        "len_dist = []\n",
        "for i in range(len(X)):\n",
        "  input_ids = tokenizer.encode(X[i], add_special_tokens = True)\n",
        "  max_len = max(len(input_ids), max_len)\n",
        "  len_dist.append(len(input_ids))\n",
        "  if len(input_ids) > 512:\n",
        "    too_big_input.append(i)\n",
        "\n",
        "print('Max length of title is ', max_len)\n",
        "df_stat = pd.DataFrame(len_dist)\n",
        "df_stat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of title is  222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>69.756913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>23.331647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>62.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>222.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  6582.000000\n",
              "mean     69.756913\n",
              "std      23.331647\n",
              "min      17.000000\n",
              "25%      55.000000\n",
              "50%      62.000000\n",
              "75%      80.000000\n",
              "max     222.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOkIs9VrlTE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# The preprocess code for the BERT\n",
        "# The following code is from https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "#The below code can be later modified to add the segment_id of setences. \n",
        "#However, since the summary + title data outperforms the validation accuracy from finBERT, I will modify this after implement the XLNet classifier\n",
        "\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            sent,  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "            truncation = True\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7dj7uzylVO5",
        "colab_type": "text"
      },
      "source": [
        "## 3. Fine-Tuning Function <a class=\"anchor\" id=\"section_3\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyERuB7vlTz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6580a828-058b-4d46-dd41-44e41e516a85"
      },
      "source": [
        "#===============================================================================\n",
        "# Declare the BERT  RNNClassifier for later train and test purpose\n",
        "# if one wants to change the model, one can modify the below section\n",
        "# without initialization of hidden and cell state\n",
        "#===============================================================================\n",
        "\n",
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertRNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Bert Model for Classification Tasks\n",
        "    \"\"\"\n",
        "    def __init__(self,  hidden_size, num_layers, num_classes, layers_to_freeze, freeze_bert=False,):\n",
        "      \"\"\"\n",
        "      @param    bert: a BertModel object\n",
        "      @param    rnn: LSTM layers\n",
        "        hidden_size: number of features in the hidden state h\n",
        "        num_layers: Number of recurrent layers\n",
        "        batch_first: If True, then the input and output tensors are provided as (batch, seq, feature)\n",
        "      @param    classifier: fc layer for the classification\n",
        "      @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "      \"\"\"\n",
        "      super(BertRNNClassifier, self).__init__()\n",
        "      self.hidden_size = hidden_size\n",
        "      self.num_layers = num_layers\n",
        "      input_size = 768\n",
        "      D_out = num_classes\n",
        "      H = 100\n",
        "      # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "      #D_in, H, D_out = 768, 100, 3\n",
        "\n",
        "      # Instantiate BERT model\n",
        "      self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n",
        "      #RNN variables\n",
        "      self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional = True)\n",
        "      '''\n",
        "      lstm output: output, (hn, cn) = lstm(input)\n",
        "      '''\n",
        "\n",
        "      # Instantiate an one-layer feed-forward classifier\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Linear(hidden_size * 2, H),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.1),\n",
        "          nn.Linear(H, D_out)\n",
        "      )\n",
        "\n",
        "      # Freeze the BERT model\n",
        "      if freeze_bert:\n",
        "          for param in self.bert.parameters():\n",
        "              param.requires_grad = False\n",
        "      else:\n",
        "        if layers_to_freeze != []:\n",
        "          for i in layers_to_freeze:\n",
        "            for param in self.bert.encoder.layer[i].parameters():\n",
        "              param.requires_grad = False  \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Feed input (BERT embedded vector) to LSTM\n",
        "        lstm_output = self.lstm(outputs[0])\n",
        "        # Take the last element of the sequence for the fully-connected layer\n",
        "        classifier_input = lstm_output[0][:,-1,:]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(classifier_input)\n",
        "\n",
        "        return logits\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 42 µs, sys: 4 µs, total: 46 µs\n",
            "Wall time: 49.1 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc8QjcruoD2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e21923cb-7ddd-4842-8efe-9e0de0cfeabb"
      },
      "source": [
        "#===============================================================================\n",
        "# Declare the BERT  RNNClassifier for later train and test purpose\n",
        "# if one wants to change the model, one can modify the below section\n",
        "# with initialization of hidden and cell state\n",
        "#===============================================================================\n",
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertRNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Bert Model for Classification Tasks\n",
        "    \"\"\"\n",
        "    def __init__(self,  hidden_size, num_layers, num_classes, layers_to_freeze, input_size = 768,  freeze_bert=False,):\n",
        "      \"\"\"\n",
        "      @param    bert: a BertModel object\n",
        "      @param    rnn: LSTM layers\n",
        "        hidden_size: number of features in the hidden state h\n",
        "        num_layers: Number of recurrent layers\n",
        "        batch_first: If True, then the input and output tensors are provided as (batch, seq, feature)\n",
        "      @param    classifier: fc layer for the classification\n",
        "      @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "      \"\"\"\n",
        "      super(BertRNNClassifier, self).__init__()\n",
        "      self.hidden_size = hidden_size\n",
        "      self.num_layers = num_layers\n",
        "      self.input_size = input_size\n",
        "      D_out = num_classes\n",
        "      H = 100\n",
        "      # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "      #D_in, H, D_out = 768, 100, 3\n",
        "\n",
        "      # Instantiate BERT model\n",
        "      self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n",
        "      #RNN variables\n",
        "      self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional = True, dropout= 0.2 )\n",
        "      '''\n",
        "      lstm output: output, (hn, cn) = lstm(input)\n",
        "      '''\n",
        "\n",
        "      # Instantiate an one-layer feed-forward classifier\n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Linear(hidden_size * 2, H),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.1),\n",
        "          nn.Linear(H, D_out)\n",
        "      )\n",
        "\n",
        "      # Freeze the BERT model\n",
        "      if freeze_bert:\n",
        "          for param in self.bert.parameters():\n",
        "              param.requires_grad = False\n",
        "      else:\n",
        "        if layers_to_freeze != []:\n",
        "          for i in layers_to_freeze:\n",
        "            for param in self.bert.encoder.layer[i].parameters():\n",
        "              param.requires_grad = False  \n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "\n",
        "        #num_layers * num_directions, batch, hidden_size\n",
        "        h0 = Variable(torch.zeros(self.num_layers*2, outputs[0].size()[0], self.hidden_size)).to(device)\n",
        "        c0 = Variable(torch.zeros(self.num_layers*2, outputs[0].size()[0], self.hidden_size)).to(device)\n",
        "\n",
        "        h0 = (nn.init.xavier_normal_(h0))\n",
        "        c0 = (nn.init.xavier_normal_(c0))\n",
        "\n",
        "        # Feed input (BERT embedded vector) to LSTM\n",
        "        lstm_output = self.lstm(outputs[0], (h0, c0))\n",
        "        # Take the last element of the sequence for the fully-connected layer\n",
        "        classifier_input = lstm_output[0][:,-1,:]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(classifier_input)\n",
        "\n",
        "        return logits\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 72 µs, sys: 8 µs, total: 80 µs\n",
            "Wall time: 90.8 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyhB1UgLljyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Initialize model for the later train purpose\n",
        "#===============================================================================\n",
        "\n",
        "def initialize_model(epochs=4, layers_to_freeze = []):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "    # Instantiate Bert Classifier\n",
        "    hidden_size = 128\n",
        "    num_layers = 4\n",
        "    num_classes = 3\n",
        "    bert_classifier = BertRNNClassifier(hidden_size= hidden_size, num_layers= num_layers, num_classes= num_classes,layers_to_freeze= layers_to_freeze, freeze_bert = False)\n",
        "\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=6e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbjKOn1xlqGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Train & Evaluate function \n",
        "#===============================================================================\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    #return float(val_loss), float(val_accuracy)\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF3h-WLGlrFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# set_seed for reproducibility \n",
        "#===============================================================================\n",
        "import random\n",
        "import time\n",
        "from torch import nn\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mltJY0n-lz80",
        "colab_type": "text"
      },
      "source": [
        "## 4. Fine-Tuning <a class=\"anchor\" id=\"section_4\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NToIo9PslsQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1b245686d4e24ab6ae1f39dbbbb7da2e",
            "3252f65d5a5c414986083ff0cc3e0a1f",
            "247f88f6ce5d4e0384253952e1550e10",
            "79395deaa6d4413ea9ed11644a33c527",
            "03016e37f9ae401f9335328dfbacad41",
            "b86262084d4a4b42a101235032e44be3",
            "a68db96dadd241609adbdab8ff1f9e58",
            "0572612babe84e418059936ba40d2ce7",
            "975d9dcea1c2420c9cfb2fbf0506ceaf",
            "5a4fbc013ef04c2d88996d00ec2c6d33",
            "abf271a19ca24f62b7740bed4488263c",
            "0238d82437f04e8cb42fb29d42c3fb9e",
            "8315c8feea204ad4a8dd4676675fda49",
            "468bbf290fbc49a499ecc173d70dd5eb",
            "a2fbc2788be648b88a1a2a7cac245a5b",
            "d32935b757b14d0e93177e10e30e0b06"
          ]
        },
        "outputId": "ea3888b0-422b-4749-bc5d-7e7ae18f6c1d"
      },
      "source": [
        "#===============================================================================\n",
        "# Part where we train using the 5-fold cv\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "#train and val are indices\n",
        "kf = KFold(n_splits=5, shuffle = True, random_state = 42)\n",
        "\n",
        "batch_size = 16\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "\n",
        "y1 = y1.astype(int)\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "  #Data Preparation\n",
        "  X_train = X[train_index]\n",
        "  X_val = X[val_index]\n",
        "  y1_train = y1[train_index]\n",
        "  y1_val = y1[val_index]\n",
        "  \n",
        "  train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "  val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
        "  train_labels = torch.tensor(y1_train.values)\n",
        "  val_labels = torch.tensor(y1_val.values)\n",
        "  \n",
        "  #Data Loader Class\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "  val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "  val_sampler = RandomSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n",
        "  \n",
        "  #Fine Tune and Evaluation\n",
        "  set_seed(42)    # Set seed for reproducibility\n",
        "  bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "  val_loss1, val_accuracy1 = train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)\n",
        "  \n",
        "  val_loss.append(val_loss1)\n",
        "  val_accuracy.append(val_accuracy1)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b245686d4e24ab6ae1f39dbbbb7da2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "975d9dcea1c2420c9cfb2fbf0506ceaf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.091269   |     -      |     -     |   17.75  \n",
            "   1    |   40    |   1.034740   |     -      |     -     |   16.55  \n",
            "   1    |   60    |   0.968487   |     -      |     -     |   16.70  \n",
            "   1    |   80    |   0.942353   |     -      |     -     |   16.70  \n",
            "   1    |   100   |   0.930926   |     -      |     -     |   16.68  \n",
            "   1    |   120   |   0.939260   |     -      |     -     |   16.77  \n",
            "   1    |   140   |   0.891924   |     -      |     -     |   16.71  \n",
            "   1    |   160   |   0.862269   |     -      |     -     |   16.69  \n",
            "   1    |   180   |   0.869467   |     -      |     -     |   16.67  \n",
            "   1    |   200   |   0.880396   |     -      |     -     |   16.65  \n",
            "   1    |   220   |   0.818793   |     -      |     -     |   16.67  \n",
            "   1    |   240   |   0.872538   |     -      |     -     |   16.71  \n",
            "   1    |   260   |   0.863567   |     -      |     -     |   16.65  \n",
            "   1    |   280   |   0.824426   |     -      |     -     |   16.68  \n",
            "   1    |   300   |   0.827016   |     -      |     -     |   16.64  \n",
            "   1    |   320   |   0.816390   |     -      |     -     |   16.63  \n",
            "   1    |   329   |   0.744083   |     -      |     -     |   6.87   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.898377   |  0.866664  |   59.05   |  297.81  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.705643   |     -      |     -     |   17.47  \n",
            "   2    |   40    |   0.658809   |     -      |     -     |   16.71  \n",
            "   2    |   60    |   0.697515   |     -      |     -     |   16.64  \n",
            "   2    |   80    |   0.677527   |     -      |     -     |   16.73  \n",
            "   2    |   100   |   0.682819   |     -      |     -     |   16.63  \n",
            "   2    |   120   |   0.685417   |     -      |     -     |   16.67  \n",
            "   2    |   140   |   0.675073   |     -      |     -     |   16.67  \n",
            "   2    |   160   |   0.703750   |     -      |     -     |   16.64  \n",
            "   2    |   180   |   0.643882   |     -      |     -     |   16.67  \n",
            "   2    |   200   |   0.668965   |     -      |     -     |   16.62  \n",
            "   2    |   220   |   0.631585   |     -      |     -     |   16.65  \n",
            "   2    |   240   |   0.583854   |     -      |     -     |   16.65  \n",
            "   2    |   260   |   0.607818   |     -      |     -     |   16.63  \n",
            "   2    |   280   |   0.626749   |     -      |     -     |   16.68  \n",
            "   2    |   300   |   0.639686   |     -      |     -     |   16.58  \n",
            "   2    |   320   |   0.649708   |     -      |     -     |   16.65  \n",
            "   2    |   329   |   0.666751   |     -      |     -     |   6.85   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.659038   |  0.823686  |   64.07   |  297.21  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9msyU6V4ls8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7721a613-aaa2-48fb-bed7-aeae4778c346"
      },
      "source": [
        "#===============================================================================\n",
        "# Print the mean loss and accuracy of the 5-fold cv\n",
        "#===============================================================================\n",
        "print('The mean validation accuracy of 5-fold cv is: ',np.mean(val_accuracy))\n",
        "print('The mean validation loss of 5-fold cv is: ', np.mean(val_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean validation accuracy of 5-fold cv is:  64.06626506024097\n",
            "The mean validation loss of 5-fold cv is:  0.8236857810652399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NMSStwXl2Z9",
        "colab_type": "text"
      },
      "source": [
        "## 5. Confusion matrix and Critical Error <a class=\"anchor\" id=\"section_5\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm7MZKCAl3cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Prediction function given the fine-tuned model\n",
        "#===============================================================================\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    val_accuracy = []\n",
        "    all_pred = []\n",
        "    all_real = []\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "        all_real.append(b_labels)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        all_pred.append(preds)\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    all_real = torch.cat(all_real)\n",
        "    all_pred = torch.cat(all_pred)\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    #val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_accuracy,all_real, all_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEPOBlPPl5YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Import py file for confusion matrtix\n",
        "#===============================================================================\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from confusion_matrix import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLW0K52Jl6Es",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2729e70f-dbf4-458b-c831-fe49b566364b"
      },
      "source": [
        "#===============================================================================\n",
        "# Make prediction for confusion matrix and critical error\n",
        "#===============================================================================\n",
        "acc,all_real, all_pred = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "critical_error = 0\n",
        "crit_error_index = []\n",
        "hit = 0\n",
        "for i in range(len(all_real)):\n",
        "  if all_real[i] == all_pred[i]:\n",
        "    hit += 1\n",
        "  if abs(all_pred[i] - all_real[i]) == 2:\n",
        "    critical_error += 1\n",
        "    crit_error_index.append(i)\n",
        "\n",
        "all_pred = all_pred.cpu().numpy()\n",
        "all_real = all_real.cpu().numpy()\n",
        "\n",
        "print('The accuracy of the model is :', hit/len(all_real))\n",
        "print('The critical error is : ',critical_error/len(all_real))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model is : 0.639331814730448\n",
            "The critical error is :  0.0387243735763098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NDj1LMAl6_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "a4a2e0f9-3b70-4df4-f10b-34c7bfdc4eaf"
      },
      "source": [
        "#===============================================================================\n",
        "# Visualization of Confusion matrix\n",
        "#===============================================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_real, all_pred)\n",
        "plot_confusion_matrix(cm,\n",
        "                      ['neg','neu', 'pos'],\n",
        "                      title='Confusion matrix',\n",
        "                      cmap=None,\n",
        "                      normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9CaBnUlMrFg",
        "colab_type": "text"
      },
      "source": [
        "## Train & Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EvsvCY0ppLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "db817d7a-5de3-4716-f1f2-0bf36c011c84"
      },
      "source": [
        "#===============================================================================\n",
        "# import py for the EDA (Easy data Augmentation)\n",
        "# original code from https://github.com/jasonwei20/eda_nlp\n",
        "#===============================================================================\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from easy_data_augmentation import *\n",
        "\n",
        "X, y1 = gen_eda(X, y1, alpha = 0.2, num_aug = 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLJBrblFMu0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8adccf34-83d4-42a7-9b46-fac136e2cafa"
      },
      "source": [
        "#===============================================================================\n",
        "# Train for prediction\n",
        "#===============================================================================\n",
        "\n",
        "batch_size = 32\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "layers_to_freeze =  [0,1,2,3,4,5,6,7]\n",
        "\n",
        "\n",
        "\n",
        "train_inputs, train_masks = preprocessing_for_bert(X)\n",
        "train_labels = torch.tensor(y1)\n",
        "#Data Loader Class\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2,layers_to_freeze =  layers_to_freeze)\n",
        "train(bert_classifier, train_dataloader, epochs=2, evaluation=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.100230   |     -      |     -     |   27.36  \n",
            "   1    |   40    |   1.095035   |     -      |     -     |   25.96  \n",
            "   1    |   60    |   1.086684   |     -      |     -     |   25.91  \n",
            "   1    |   80    |   1.065912   |     -      |     -     |   25.92  \n",
            "   1    |   100   |   1.058796   |     -      |     -     |   25.97  \n",
            "   1    |   120   |   1.017956   |     -      |     -     |   25.98  \n",
            "   1    |   140   |   1.005530   |     -      |     -     |   26.00  \n",
            "   1    |   160   |   1.006064   |     -      |     -     |   25.99  \n",
            "   1    |   180   |   0.992976   |     -      |     -     |   26.11  \n",
            "   1    |   200   |   0.981256   |     -      |     -     |   25.81  \n",
            "   1    |   220   |   0.957721   |     -      |     -     |   25.88  \n",
            "   1    |   240   |   0.959159   |     -      |     -     |   25.76  \n",
            "   1    |   260   |   0.954940   |     -      |     -     |   25.82  \n",
            "   1    |   280   |   0.929862   |     -      |     -     |   25.76  \n",
            "   1    |   300   |   0.938798   |     -      |     -     |   25.82  \n",
            "   1    |   320   |   0.941969   |     -      |     -     |   25.78  \n",
            "   1    |   340   |   0.897792   |     -      |     -     |   25.78  \n",
            "   1    |   360   |   0.909360   |     -      |     -     |   25.75  \n",
            "   1    |   380   |   0.851508   |     -      |     -     |   25.79  \n",
            "   1    |   400   |   0.894308   |     -      |     -     |   25.83  \n",
            "   1    |   420   |   0.870048   |     -      |     -     |   25.92  \n",
            "   1    |   440   |   0.880139   |     -      |     -     |   25.97  \n",
            "   1    |   460   |   0.862524   |     -      |     -     |   25.82  \n",
            "   1    |   480   |   0.907797   |     -      |     -     |   25.86  \n",
            "   1    |   500   |   0.888409   |     -      |     -     |   25.84  \n",
            "   1    |   520   |   0.819729   |     -      |     -     |   25.78  \n",
            "   1    |   540   |   0.826927   |     -      |     -     |   25.82  \n",
            "   1    |   560   |   0.832137   |     -      |     -     |   25.74  \n",
            "   1    |   580   |   0.765726   |     -      |     -     |   25.88  \n",
            "   1    |   600   |   0.833518   |     -      |     -     |   25.79  \n",
            "   1    |   620   |   0.809945   |     -      |     -     |   25.77  \n",
            "   1    |   640   |   0.804975   |     -      |     -     |   25.78  \n",
            "   1    |   660   |   0.761218   |     -      |     -     |   25.75  \n",
            "   1    |   680   |   0.809263   |     -      |     -     |   25.69  \n",
            "   1    |   700   |   0.745982   |     -      |     -     |   25.83  \n",
            "   1    |   720   |   0.800603   |     -      |     -     |   25.77  \n",
            "   1    |   740   |   0.801671   |     -      |     -     |   25.78  \n",
            "   1    |   760   |   0.750061   |     -      |     -     |   25.75  \n",
            "   1    |   780   |   0.794122   |     -      |     -     |   25.77  \n",
            "   1    |   800   |   0.781100   |     -      |     -     |   25.80  \n",
            "   1    |   820   |   0.732467   |     -      |     -     |   25.74  \n",
            "   1    |   840   |   0.757898   |     -      |     -     |   25.74  \n",
            "   1    |   860   |   0.767381   |     -      |     -     |   25.76  \n",
            "   1    |   880   |   0.734377   |     -      |     -     |   25.77  \n",
            "   1    |   900   |   0.731642   |     -      |     -     |   25.78  \n",
            "   1    |   920   |   0.738985   |     -      |     -     |   25.76  \n",
            "   1    |   940   |   0.738757   |     -      |     -     |   25.76  \n",
            "   1    |   960   |   0.757305   |     -      |     -     |   25.78  \n",
            "   1    |   980   |   0.670137   |     -      |     -     |   25.80  \n",
            "   1    |  1000   |   0.725026   |     -      |     -     |   25.79  \n",
            "   1    |  1020   |   0.652089   |     -      |     -     |   25.75  \n",
            "   1    |  1040   |   0.702180   |     -      |     -     |   25.80  \n",
            "   1    |  1060   |   0.715036   |     -      |     -     |   25.75  \n",
            "   1    |  1080   |   0.661909   |     -      |     -     |   25.77  \n",
            "   1    |  1100   |   0.664110   |     -      |     -     |   25.76  \n",
            "   1    |  1120   |   0.733709   |     -      |     -     |   25.70  \n",
            "   1    |  1140   |   0.674788   |     -      |     -     |   25.78  \n",
            "   1    |  1160   |   0.669978   |     -      |     -     |   25.75  \n",
            "   1    |  1180   |   0.649475   |     -      |     -     |   25.77  \n",
            "   1    |  1200   |   0.664353   |     -      |     -     |   25.76  \n",
            "   1    |  1220   |   0.711040   |     -      |     -     |   25.69  \n",
            "   1    |  1240   |   0.664258   |     -      |     -     |   25.69  \n",
            "   1    |  1260   |   0.673827   |     -      |     -     |   25.77  \n",
            "   1    |  1280   |   0.692668   |     -      |     -     |   25.78  \n",
            "   1    |  1300   |   0.639833   |     -      |     -     |   25.79  \n",
            "   1    |  1320   |   0.605296   |     -      |     -     |   25.77  \n",
            "   1    |  1340   |   0.589417   |     -      |     -     |   25.73  \n",
            "   1    |  1360   |   0.657188   |     -      |     -     |   25.77  \n",
            "   1    |  1380   |   0.663227   |     -      |     -     |   25.73  \n",
            "   1    |  1400   |   0.584954   |     -      |     -     |   25.76  \n",
            "   1    |  1420   |   0.614291   |     -      |     -     |   25.92  \n",
            "   1    |  1439   |   0.630216   |     -      |     -     |   24.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.494968   |     -      |     -     |   27.28  \n",
            "   2    |   40    |   0.501633   |     -      |     -     |   26.14  \n",
            "   2    |   60    |   0.513186   |     -      |     -     |   26.09  \n",
            "   2    |   80    |   0.495916   |     -      |     -     |   26.06  \n",
            "   2    |   100   |   0.516634   |     -      |     -     |   26.07  \n",
            "   2    |   120   |   0.444800   |     -      |     -     |   26.05  \n",
            "   2    |   140   |   0.496483   |     -      |     -     |   25.98  \n",
            "   2    |   160   |   0.523049   |     -      |     -     |   25.95  \n",
            "   2    |   180   |   0.481864   |     -      |     -     |   25.93  \n",
            "   2    |   200   |   0.442871   |     -      |     -     |   25.96  \n",
            "   2    |   220   |   0.492261   |     -      |     -     |   25.94  \n",
            "   2    |   240   |   0.499752   |     -      |     -     |   25.94  \n",
            "   2    |   260   |   0.475787   |     -      |     -     |   25.90  \n",
            "   2    |   280   |   0.505845   |     -      |     -     |   26.00  \n",
            "   2    |   300   |   0.493498   |     -      |     -     |   25.95  \n",
            "   2    |   320   |   0.433220   |     -      |     -     |   25.98  \n",
            "   2    |   340   |   0.472764   |     -      |     -     |   25.95  \n",
            "   2    |   360   |   0.490408   |     -      |     -     |   26.01  \n",
            "   2    |   380   |   0.489201   |     -      |     -     |   25.98  \n",
            "   2    |   400   |   0.463909   |     -      |     -     |   25.93  \n",
            "   2    |   420   |   0.403760   |     -      |     -     |   26.01  \n",
            "   2    |   440   |   0.459516   |     -      |     -     |   26.01  \n",
            "   2    |   460   |   0.441053   |     -      |     -     |   26.01  \n",
            "   2    |   480   |   0.478705   |     -      |     -     |   25.96  \n",
            "   2    |   500   |   0.423017   |     -      |     -     |   25.93  \n",
            "   2    |   520   |   0.440689   |     -      |     -     |   25.93  \n",
            "   2    |   540   |   0.455672   |     -      |     -     |   25.90  \n",
            "   2    |   560   |   0.448988   |     -      |     -     |   25.95  \n",
            "   2    |   580   |   0.469729   |     -      |     -     |   25.97  \n",
            "   2    |   600   |   0.485321   |     -      |     -     |   25.92  \n",
            "   2    |   620   |   0.432627   |     -      |     -     |   25.91  \n",
            "   2    |   640   |   0.389330   |     -      |     -     |   25.95  \n",
            "   2    |   660   |   0.393455   |     -      |     -     |   26.01  \n",
            "   2    |   680   |   0.393304   |     -      |     -     |   25.97  \n",
            "   2    |   700   |   0.437014   |     -      |     -     |   25.87  \n",
            "   2    |   720   |   0.364043   |     -      |     -     |   25.95  \n",
            "   2    |   740   |   0.396803   |     -      |     -     |   25.89  \n",
            "   2    |   760   |   0.454614   |     -      |     -     |   25.96  \n",
            "   2    |   780   |   0.365234   |     -      |     -     |   25.92  \n",
            "   2    |   800   |   0.367192   |     -      |     -     |   25.96  \n",
            "   2    |   820   |   0.424712   |     -      |     -     |   25.97  \n",
            "   2    |   840   |   0.478619   |     -      |     -     |   25.93  \n",
            "   2    |   860   |   0.395072   |     -      |     -     |   25.98  \n",
            "   2    |   880   |   0.392545   |     -      |     -     |   26.01  \n",
            "   2    |   900   |   0.387763   |     -      |     -     |   26.00  \n",
            "   2    |   920   |   0.387508   |     -      |     -     |   25.98  \n",
            "   2    |   940   |   0.370015   |     -      |     -     |   25.95  \n",
            "   2    |   960   |   0.401955   |     -      |     -     |   25.97  \n",
            "   2    |   980   |   0.368400   |     -      |     -     |   25.90  \n",
            "   2    |  1000   |   0.432313   |     -      |     -     |   25.87  \n",
            "   2    |  1020   |   0.399042   |     -      |     -     |   25.80  \n",
            "   2    |  1040   |   0.384370   |     -      |     -     |   25.77  \n",
            "   2    |  1060   |   0.383412   |     -      |     -     |   25.79  \n",
            "   2    |  1080   |   0.350489   |     -      |     -     |   25.76  \n",
            "   2    |  1100   |   0.356497   |     -      |     -     |   25.77  \n",
            "   2    |  1120   |   0.322436   |     -      |     -     |   25.78  \n",
            "   2    |  1140   |   0.367165   |     -      |     -     |   25.72  \n",
            "   2    |  1160   |   0.365620   |     -      |     -     |   25.84  \n",
            "   2    |  1180   |   0.330852   |     -      |     -     |   25.78  \n",
            "   2    |  1200   |   0.381710   |     -      |     -     |   25.82  \n",
            "   2    |  1220   |   0.351615   |     -      |     -     |   25.81  \n",
            "   2    |  1240   |   0.347313   |     -      |     -     |   25.80  \n",
            "   2    |  1260   |   0.377124   |     -      |     -     |   25.77  \n",
            "   2    |  1280   |   0.314693   |     -      |     -     |   25.81  \n",
            "   2    |  1300   |   0.319627   |     -      |     -     |   25.77  \n",
            "   2    |  1320   |   0.315574   |     -      |     -     |   25.75  \n",
            "   2    |  1340   |   0.334997   |     -      |     -     |   25.82  \n",
            "   2    |  1360   |   0.382349   |     -      |     -     |   25.79  \n",
            "   2    |  1380   |   0.346920   |     -      |     -     |   25.77  \n",
            "   2    |  1400   |   0.348008   |     -      |     -     |   25.81  \n",
            "   2    |  1420   |   0.378976   |     -      |     -     |   25.77  \n",
            "   2    |  1439   |   0.385060   |     -      |     -     |   24.29  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDFxCtKBofG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Prediction function \n",
        "#===============================================================================\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    val_accuracy = []\n",
        "    all_pred = []\n",
        "    all_real = []\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "        all_real.append(b_labels)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        all_pred.append(preds)\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    all_real = torch.cat(all_real)\n",
        "    all_pred = torch.cat(all_pred)\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    #val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_accuracy,all_real, all_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nYJTVvAogB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "dba44839-a90c-4823-fd8c-f4b12a7bc57c"
      },
      "source": [
        "#===============================================================================\n",
        "# Test the trained model\n",
        "#===============================================================================\n",
        "df_test = pd.read_json('/content/drive/My Drive/KIS data/test_data.json')\n",
        "\n",
        "print(len(df_test))\n",
        "idx_to_remove = []\n",
        "for i in range(len(df_test)):\n",
        "  if type(df_test['summary'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "  if type(df_test['title'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "\n",
        "df_test = df_test.iloc[list(set(df_test.index) - set(idx_to_remove))]\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_test['title_summary'] = df_test['title'] + ' ' + df_test['summary']\n",
        "df_test= df_test.drop(df_test[df_test['title_summary'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "df_test= df_test.drop(df_test[df_test['importance'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "df_test= df_test.drop(df_test[df_test['sentiment'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "title_summary_len = [len(df_test['title_summary'][i].split(' ')) for i in range(len(df_test))]\n",
        "df_stat = pd.DataFrame(title_summary_len)\n",
        "df_stat.describe()\n",
        "print(len(df_test))\n",
        "\n",
        "X_test, y1_test, y2_test = df_test['title_summary'], df_test['sentiment'].apply(int), df_test['importance'].apply(int)\n",
        "y1_test_values, y2_test_values = y1_test.values, y2_test.values\n",
        "\n",
        "label_count_test_1, label_count_test_2 = [0,0,0], [0,0,0]\n",
        "for i in range(len(y1_test)):\n",
        "  label_count_test_1[y1_test_values[i]] += 1\n",
        "  label_count_test_2[y2_test_values[i]] += 1\n",
        "\n",
        "print(label_count_test_1, label_count_test_2)\n",
        "print([round(label_count_test_1[i]/sum(label_count_test_1),3) for i in range(len(label_count_test_1))], [round(label_count_test_2[i]/sum(label_count_test_2),3) for i in range(len(label_count_test_2))])\n",
        "\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
        "test_labels = torch.tensor(y1_test)\n",
        "#Data Loader Class\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)\n",
        "\n",
        "acc,all_real, all_pred = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "critical_error = 0\n",
        "crit_error_index = []\n",
        "hit = 0\n",
        "for i in range(len(all_real)):\n",
        "  if all_real[i] == all_pred[i]:\n",
        "    hit += 1\n",
        "  if abs(all_pred[i] - all_real[i]) == 2:\n",
        "    critical_error += 1\n",
        "    crit_error_index.append(i)\n",
        "\n",
        "all_pred = all_pred.cpu().numpy()\n",
        "all_real = all_real.cpu().numpy()\n",
        "\n",
        "print('The accuracy of the model is :', hit/len(all_real))\n",
        "print('The critical error is : ',critical_error/len(all_real))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2898\n",
            "2866\n",
            "[366, 1585, 915] [1052, 918, 896]\n",
            "[0.128, 0.553, 0.319] [0.367, 0.32, 0.313]\n",
            "The accuracy of the model is : 0.40648988136775993\n",
            "The critical error is :  0.12107466852756454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCHReiszMxJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from confusion_matrix import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt_CZLcwMx3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "2b35f918-d9a5-4d25-c870-0f761ba0b9e6"
      },
      "source": [
        "#===============================================================================\n",
        "# Visualization of confusion matrix\n",
        "#===============================================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_real, all_pred)\n",
        "plot_confusion_matrix(cm,\n",
        "                      ['neg','neu', 'pos'],\n",
        "                      title='Confusion matrix',\n",
        "                      cmap=None,\n",
        "                      normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDhk_QJ6G_0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}