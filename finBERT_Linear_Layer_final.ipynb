{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finBERT_Linear_Layer_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2603861de5d24e33ad1b60c7430d7868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_191e0531c5d64723a902e6cd5794dd69",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_891e9770cf9f4f45bb985fec5db6c52b",
              "IPY_MODEL_40f53ff77b324194b5319ea9a7dd2b74"
            ]
          }
        },
        "191e0531c5d64723a902e6cd5794dd69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "891e9770cf9f4f45bb985fec5db6c52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_44525ec542924ecf88977864e277e43e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1287,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1287,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2b10adca986465083ed4984d9bc7ee1"
          }
        },
        "40f53ff77b324194b5319ea9a7dd2b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c37090a368fe4515a78e65fccc17e75b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.29k/1.29k [00:06&lt;00:00, 186B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62a17058f370418082a7c7b2e6b944bc"
          }
        },
        "44525ec542924ecf88977864e277e43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2b10adca986465083ed4984d9bc7ee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c37090a368fe4515a78e65fccc17e75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62a17058f370418082a7c7b2e6b944bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb5adf7b35dd478db9e83d435d7632bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_098f76c5e87c4e3b9d78dbd26a1c30cf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c46a9f485bd4f76b7668fe33419bf9d",
              "IPY_MODEL_911f472b867845f5bd8a7bfa3782361b"
            ]
          }
        },
        "098f76c5e87c4e3b9d78dbd26a1c30cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c46a9f485bd4f76b7668fe33419bf9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1599131bc0844cf49a0a563e2de8f0e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ccf2f0faa954661a706e4395d9db931"
          }
        },
        "911f472b867845f5bd8a7bfa3782361b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a68a29acd9a48a2b9d34d878b5170f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:02&lt;00:00, 72.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19159223ef944bb0921e5dafbbf256e3"
          }
        },
        "1599131bc0844cf49a0a563e2de8f0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ccf2f0faa954661a706e4395d9db931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a68a29acd9a48a2b9d34d878b5170f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19159223ef944bb0921e5dafbbf256e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2385c3a5453e4f66866c2103bb159744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1160044b35c5446a8e9ba284c5e2a83e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca12ae161fb843eea06c771d519ef49a",
              "IPY_MODEL_c3a45152e3364b6b845657afa09b13f2"
            ]
          }
        },
        "1160044b35c5446a8e9ba284c5e2a83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca12ae161fb843eea06c771d519ef49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e52c48b7b28420ab497c5e953adfd32",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7809db7ce4124348bdcf64e53f8fcbe2"
          }
        },
        "c3a45152e3364b6b845657afa09b13f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_17bc050de8654bcfb192bd958b1d6657",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:02&lt;00:00, 47.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_226b70294a6b481e8686ae03e6cb2d70"
          }
        },
        "6e52c48b7b28420ab497c5e953adfd32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7809db7ce4124348bdcf64e53f8fcbe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17bc050de8654bcfb192bd958b1d6657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "226b70294a6b481e8686ae03e6cb2d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8db1ec5266074fb89f5c3583b4a9c2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3cecea0a59764806baf23661f0a22f4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2c4bb714eae4f2992e9ecbca3ad016d",
              "IPY_MODEL_9c6fc12fbad74086a3887103642882ea"
            ]
          }
        },
        "3cecea0a59764806baf23661f0a22f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2c4bb714eae4f2992e9ecbca3ad016d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_15cae8d0f63649c68ad0d843d1927379",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 40,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1a2452098c14ff180aba52322d071a3"
          }
        },
        "9c6fc12fbad74086a3887103642882ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3dab9f2637624b08b0847b6efa9d9ca3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 40.0/40.0 [00:00&lt;00:00, 49.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad8f3f0132fd42088fb1634119662279"
          }
        },
        "15cae8d0f63649c68ad0d843d1927379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1a2452098c14ff180aba52322d071a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3dab9f2637624b08b0847b6efa9d9ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad8f3f0132fd42088fb1634119662279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz2bLUAlnIhy",
        "colab_type": "text"
      },
      "source": [
        "# About the notebook\n",
        "\n",
        "The following notebook contains the FinBert model with Linear layer for the classification purpose (sentiment analysis & text classification). The notebook has a following order:\n",
        "\n",
        "1. [Data Import & Preprocess](#section_1)\n",
        "2. [Tokenization & Preprocess for model](#section_2)\n",
        "3. [Fine-Tuning Function](#section_3)\n",
        "4. [Fine-Tuning](#section_4)\n",
        "5. [Confusion matrix & Critical Error](#section_5)\n",
        "6. [Train & Test](#section_6)\n",
        "\n",
        "Please refer to the BERT_Linear_layer for the purpose of the note book.\n",
        "The original idea is from [source_code](https://github.com/ProsusAI/finBERT) and [article](https://arxiv.org/abs/1908.10063). Please follow the link for those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtX4ikMThA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "c6378c7f-c53e-45ff-c1d3-95302cf38a35"
      },
      "source": [
        "#===============================================================================\n",
        "# Import Libraries and Download module necessary for the deep learning\n",
        "#===============================================================================\n",
        "\n",
        "#huggingface library installation\n",
        "!pip install transformers\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from transformers import BertForTokenClassification, AdamW, BertConfig, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import transformers\n",
        "from torch.utils.data import TensorDataset, random_split,DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import datetime\n",
        "from platform import python_version\n",
        "import sklearn\n",
        "import torch\n",
        "\n",
        "#Using Colab GPU for training\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "#To confirm that we are using GPU for the training later\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 8.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\r\u001b[K     |▍                               | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 27.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 32.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 21.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 17.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 20.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 15.5MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 16.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 16.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102kB 14.6MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122kB 14.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 194kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 235kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 266kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 296kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 327kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 389kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 419kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 450kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 471kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 481kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 501kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 512kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 532kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 542kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 563kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 573kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 593kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 604kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 624kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 655kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 665kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 675kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 686kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 696kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 706kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 727kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 737kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 747kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 757kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 768kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 778kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 788kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 808kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 819kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 829kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 839kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 849kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 860kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 870kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 880kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 890kB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 66kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=73f6a9abe16214393022783f61d22a12fdb12341591f96e22925de247d457e2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYAUXs1VT3zx",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data Import & Preprocess <a class=\"anchor\" id=\"section_1\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPb1W0TXT2qZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "70ab4b84-72ec-4333-b9b7-3d12d47deeb8"
      },
      "source": [
        "#===============================================================================\n",
        "# Load Google Drive for the data\n",
        "#===============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_direction = '/content/drive/My Drive/KIS data/CIMS_news_with_bertext_sum_full.xlsx'\n",
        "df = pd.read_excel(file_direction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la_j5vr0T5vo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8179d1b2-06c2-4828-8ec4-c4e54404b79f"
      },
      "source": [
        "#===============================================================================\n",
        "# Text Data & label preprocess for the model\n",
        "#===============================================================================\n",
        "\n",
        "print(len(df))\n",
        "idx_to_remove = []\n",
        "for i in range(len(df)):\n",
        "  if type(df['summary_v2'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "\n",
        "df = df.iloc[list(set(df.index) - set(idx_to_remove))]\n",
        "df.index = np.arange(0, len(df))\n",
        "print(len(df))\n",
        "\n",
        "df['importance'] = df['score']\n",
        "\n",
        "#score by daumsoft:\n",
        "#sentiment: 3 - positive, 2 - neutral, 1 - negative\n",
        "#score: 3 - important, 2 - normal, 1 - negligible \n",
        "for i in range(len(df)):\n",
        "  if df.loc[i,'sentiment'] == 3:\n",
        "    df.loc[i,'sentiment'] = 2\n",
        "  elif df.loc[i,'sentiment'] == 2:\n",
        "    df.loc[i,'sentiment'] = 1\n",
        "  elif df.loc[i,'sentiment'] == 1:\n",
        "    df.loc[i,'sentiment'] = 0\n",
        "  if df.loc[i, 'score'] == 1:\n",
        "    df.loc[i, 'importance'] = 0\n",
        "  elif df.loc[i, 'importance'] == 2:\n",
        "    df.loc[i, 'importance'] = 1\n",
        "  elif df.loc[i, 'importance'] == 3:\n",
        "    df.loc[i, 'importance'] = 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6584\n",
            "6582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy5DuwbFT6qx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "974ca705-f216-4aa1-9f6d-16e6a6164d54"
      },
      "source": [
        "#===============================================================================\n",
        "# Prepare text data (Title + summary) for the model\n",
        "#===============================================================================\n",
        "df['title_summary'] = df['title'] + ' ' + df['summary_v2']\n",
        "title_summary_len = [len(df['title_summary'][i].split(' ')) for i in range(len(df))]\n",
        "df_stat = pd.DataFrame(title_summary_len)\n",
        "df_stat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>52.518839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.800150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>47.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>183.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  6582.000000\n",
              "mean     52.518839\n",
              "std      17.800150\n",
              "min      13.000000\n",
              "25%      42.000000\n",
              "50%      47.000000\n",
              "75%      60.000000\n",
              "max     183.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvyrhK9kT7k5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "94f6ab94-992a-4ca9-d3df-b89fe513952c"
      },
      "source": [
        "#===============================================================================\n",
        "# Data Preprocess & Distribution of labels (sentiment & importance)\n",
        "#===============================================================================\n",
        "X, y1, y2 = df['title_summary'], df['sentiment'], df['importance']\n",
        "y1_values, y2_values = y1.values, y2.values\n",
        "\n",
        "label_count_1, label_count_2 = [0,0,0], [0,0,0]\n",
        "for i in range(len(y1)):\n",
        "  label_count_1[y1_values[i]] += 1\n",
        "  label_count_2[y2_values[i]] += 1\n",
        "\n",
        "print(label_count_1, label_count_2)\n",
        "print([round(label_count_1[i]/sum(label_count_1),3) for i in range(len(label_count_1))], [round(label_count_2[i]/sum(label_count_2),3) for i in range(len(label_count_2))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1315, 3245, 2022] [2045, 2432, 2105]\n",
            "[0.2, 0.493, 0.307] [0.311, 0.369, 0.32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOmOrVM9hcVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# In order to fine-tune BERT for the importance classification\n",
        "#===============================================================================\n",
        "X, y1, y2 = df['title_summary'], df['importance'], df['importance']\n",
        "y1_values, y2_values = y1.values, y2.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgGCaMlDUOr5",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tokenization & Preprocess for model <a class=\"anchor\" id=\"section_2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCicFFDZT8up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291,
          "referenced_widgets": [
            "2603861de5d24e33ad1b60c7430d7868",
            "191e0531c5d64723a902e6cd5794dd69",
            "891e9770cf9f4f45bb985fec5db6c52b",
            "40f53ff77b324194b5319ea9a7dd2b74",
            "44525ec542924ecf88977864e277e43e",
            "a2b10adca986465083ed4984d9bc7ee1",
            "c37090a368fe4515a78e65fccc17e75b",
            "62a17058f370418082a7c7b2e6b944bc",
            "fb5adf7b35dd478db9e83d435d7632bb",
            "098f76c5e87c4e3b9d78dbd26a1c30cf",
            "3c46a9f485bd4f76b7668fe33419bf9d",
            "911f472b867845f5bd8a7bfa3782361b",
            "1599131bc0844cf49a0a563e2de8f0e5",
            "3ccf2f0faa954661a706e4395d9db931",
            "5a68a29acd9a48a2b9d34d878b5170f9",
            "19159223ef944bb0921e5dafbbf256e3",
            "2385c3a5453e4f66866c2103bb159744",
            "1160044b35c5446a8e9ba284c5e2a83e",
            "ca12ae161fb843eea06c771d519ef49a",
            "c3a45152e3364b6b845657afa09b13f2",
            "6e52c48b7b28420ab497c5e953adfd32",
            "7809db7ce4124348bdcf64e53f8fcbe2",
            "17bc050de8654bcfb192bd958b1d6657",
            "226b70294a6b481e8686ae03e6cb2d70",
            "8db1ec5266074fb89f5c3583b4a9c2dd",
            "3cecea0a59764806baf23661f0a22f4d",
            "f2c4bb714eae4f2992e9ecbca3ad016d",
            "9c6fc12fbad74086a3887103642882ea",
            "15cae8d0f63649c68ad0d843d1927379",
            "d1a2452098c14ff180aba52322d071a3",
            "3dab9f2637624b08b0847b6efa9d9ca3",
            "ad8f3f0132fd42088fb1634119662279"
          ]
        },
        "outputId": "e5a55e7f-f8fc-4099-d429-40b2ccdad5f7"
      },
      "source": [
        "#===============================================================================\n",
        "# Download BERT tokenizer from huggingface\n",
        "#===============================================================================\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ipuneetrathore/bert-base-cased-finetuned-finBERT\")\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', X[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(X[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2603861de5d24e33ad1b60c7430d7868",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1287.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb5adf7b35dd478db9e83d435d7632bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2385c3a5453e4f66866c2103bb159744",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8db1ec5266074fb89f5c3583b4a9c2dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=40.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Original:  Google Helping Mobile Publishing? Some Publishers Are Not So Sure In October, the software developer Alex Kras created a stir when he wrote a post titled “Google May Be Stealing Your Mobile Traffic,” in which he recounted what had happened when he used AMP on his technology blog. Joey Marburger, director of products for The Post, said that its readers were scrolling further on AMP stories, but that it was building its own fast system to gain greater control over ads and features. “\n",
            "Tokenized:  ['Google', 'Help', '##ing', 'Mobile', 'Publishing', '?', 'Some', 'Publishers', 'Are', 'Not', 'So', 'Sure', 'In', 'October', ',', 'the', 'software', 'developer', 'Alex', 'K', '##ras', 'created', 'a', 'stir', 'when', 'he', 'wrote', 'a', 'post', 'titled', '“', 'Google', 'May', 'Be', 'St', '##eal', '##ing', 'Your', 'Mobile', 'Traffic', ',', '”', 'in', 'which', 'he', 'recounted', 'what', 'had', 'happened', 'when', 'he', 'used', 'AM', '##P', 'on', 'his', 'technology', 'blog', '.', 'Joey', 'Mar', '##burg', '##er', ',', 'director', 'of', 'products', 'for', 'The', 'Post', ',', 'said', 'that', 'its', 'readers', 'were', 'scroll', '##ing', 'further', 'on', 'AM', '##P', 'stories', ',', 'but', 'that', 'it', 'was', 'building', 'its', 'own', 'fast', 'system', 'to', 'gain', 'greater', 'control', 'over', 'ads', 'and', 'features', '.', '“']\n",
            "Token IDs:  [7986, 12056, 1158, 8410, 7045, 136, 1789, 12748, 2372, 1753, 1573, 6542, 1130, 1357, 117, 1103, 3594, 9991, 3230, 148, 7297, 1687, 170, 17977, 1165, 1119, 1724, 170, 2112, 3334, 789, 7986, 1318, 4108, 1457, 13003, 1158, 2353, 8410, 15727, 117, 790, 1107, 1134, 1119, 25546, 1184, 1125, 2171, 1165, 1119, 1215, 6586, 2101, 1113, 1117, 2815, 10679, 119, 9300, 9751, 3410, 1200, 117, 1900, 1104, 2982, 1111, 1109, 3799, 117, 1163, 1115, 1157, 8460, 1127, 21105, 1158, 1748, 1113, 6586, 2101, 2801, 117, 1133, 1115, 1122, 1108, 1459, 1157, 1319, 2698, 1449, 1106, 4361, 3407, 1654, 1166, 17641, 1105, 1956, 119, 789]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlCODCL5UQnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "2207007b-cb0d-44df-a9d3-3285af04f6af"
      },
      "source": [
        "#===============================================================================\n",
        "# In order to decide the MAX_LEN for padding and truncation purpose, check the \n",
        "# distribution of length of text data\n",
        "#===============================================================================\n",
        "\n",
        "max_len = 0\n",
        "too_big_input = []\n",
        "len_dist = []\n",
        "for i in range(len(X)):\n",
        "  input_ids = tokenizer.encode(X[i], add_special_tokens = True)\n",
        "  max_len = max(len(input_ids), max_len)\n",
        "  len_dist.append(len(input_ids))\n",
        "  if len(input_ids) > 512:\n",
        "    too_big_input.append(i)\n",
        "\n",
        "print('Max length of title is ', max_len)\n",
        "df_stat = pd.DataFrame(len_dist)\n",
        "df_stat.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of title is  241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6582.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>73.360529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>24.624694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>58.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>66.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>84.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>241.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  6582.000000\n",
              "mean     73.360529\n",
              "std      24.624694\n",
              "min      19.000000\n",
              "25%      58.000000\n",
              "50%      66.000000\n",
              "75%      84.000000\n",
              "max     241.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-UD9bEIURlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# The preprocess code for the BERT\n",
        "# The following code is from https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "#===============================================================================\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "def preprocessing_for_finbert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            sent,  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "            truncation = True\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPoKEO3EUayB",
        "colab_type": "text"
      },
      "source": [
        "## 3. Fine-Tuning Function <a class=\"anchor\" id=\"section_3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc7yAwGiUbDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Declare the BERT Classifier for later train and test purpose\n",
        "# if one wants to change the model, one can modify the below section\n",
        "#===============================================================================\n",
        "from torch import nn\n",
        "\n",
        "class Identity(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Identity, self).__init__()\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "    \n",
        "class finBertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False, layers_to_freeze = []):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(finBertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 100, 3\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.finbert = AutoModelForSequenceClassification.from_pretrained(\"ipuneetrathore/bert-base-cased-finetuned-finBERT\")\n",
        "        \n",
        "        self.finbert.classifier = Identity()\n",
        "        self.finbert.dropout = Identity() #will not use dropout (on top of pooling layer)\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.finbert.parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "          if layers_to_freeze != []:\n",
        "            for i in layers_to_freeze:\n",
        "              for param in self.finbert.bert.encoder.layer[i].parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.finbert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier1(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvP0UOywYjsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Initialize model for the later train purpose\n",
        "#===============================================================================\n",
        "\n",
        "def initialize_model(epochs=4, layers_to_freeze = []):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "    # Instantiate Bert Classifier\n",
        "    #finbert_classifier = AutoModelForSequenceClassification.from_pretrained(\"ipuneetrathore/bert-base-cased-finetuned-finBERT\")\n",
        "    finbert_classifier = finBertClassifier(freeze_bert = False, layers_to_freeze = layers_to_freeze)\n",
        "\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    finbert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(finbert_classifier.parameters(),\n",
        "                      lr=6e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return finbert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-DnQcL1YnME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Train & Evaluate function \n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "import random\n",
        "import time\n",
        "from torch import nn\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    #return float(val_loss), float(val_accuracy)\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-WSMmH9YvYd",
        "colab_type": "text"
      },
      "source": [
        "## 4. Fine-Tuning <a class=\"anchor\" id=\"section_4\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olp30yuxYvhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Part where we train using the 5-fold cv\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "#train and val are indices\n",
        "kf = KFold(n_splits=5, shuffle = True)\n",
        "\n",
        "batch_size = 16\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "\n",
        "y1 = y1.astype(int)\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "  #Data Preparation\n",
        "  X_train = X[train_index]\n",
        "  X_val = X[val_index]\n",
        "  y1_train = y1[train_index]\n",
        "  y1_val = y1[val_index]\n",
        "  \n",
        "  train_inputs, train_masks = preprocessing_for_finbert(X_train)\n",
        "  val_inputs, val_masks = preprocessing_for_finbert(X_val)\n",
        "  train_labels = torch.tensor(y1_train.values)\n",
        "  val_labels = torch.tensor(y1_val.values)\n",
        "  \n",
        "  #Data Loader Class\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "  val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "  val_sampler = RandomSampler(val_data)\n",
        "  val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n",
        "\n",
        "  #Fine Tune and Evaluation\n",
        "  set_seed(42)    # Set seed for reproducibility\n",
        "  finbert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "  val_loss1, val_accuracy1 = train(finbert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)\n",
        "  \n",
        "  val_loss.append(val_loss1)\n",
        "  val_accuracy.append(val_accuracy1)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJFPRDyTYvEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Print the mean loss and accuracy of the 5-fold cv\n",
        "#===============================================================================\n",
        "print('The mean validation accuracy of 5-fold cv is: ',np.mean(val_accuracy))\n",
        "print('The mean validation loss of 5-fold cv is: ', np.mean(val_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIZPUGQcY1Gq",
        "colab_type": "text"
      },
      "source": [
        "## 5. Confusion matrix & Critical Error <a class=\"anchor\" id=\"section_5\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcT2vwcQ5XbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# import py for the EDA (Easy data Augmentation)\n",
        "# original code from https://github.com/jasonwei20/eda_nlp\n",
        "#===============================================================================\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from easy_data_augmentation import *\n",
        "\n",
        "X, y1 = gen_eda(X, y1, alpha = 0.2, num_aug = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaBPqQ2cY1_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Prediction function given the fine-tuned model\n",
        "#===============================================================================\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    val_accuracy = []\n",
        "    all_pred = []\n",
        "    all_real = []\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "        all_real.append(b_labels)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        all_pred.append(preds)\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    all_real = torch.cat(all_real)\n",
        "    all_pred = torch.cat(all_pred)\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    #val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_accuracy,all_real, all_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXCUGUT_Y36_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Import py file for confusion matrtix\n",
        "#===============================================================================\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from confusion_matrix import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2Zh83Q9Y_P-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Make prediction for confusion matrix and critical error\n",
        "#===============================================================================\n",
        "acc,all_real, all_pred = bert_predict(bert_classifier, val_dataloader)\n",
        "\n",
        "critical_error = 0\n",
        "crit_error_index = []\n",
        "hit = 0\n",
        "for i in range(len(all_real)):\n",
        "  if all_real[i] == all_pred[i]:\n",
        "    hit += 1\n",
        "  if abs(all_pred[i] - all_real[i]) == 2:\n",
        "    critical_error += 1\n",
        "    crit_error_index.append(i)\n",
        "\n",
        "all_pred = all_pred.cpu().numpy()\n",
        "all_real = all_real.cpu().numpy()\n",
        "\n",
        "print('The accuracy of the model is :', hit/len(all_real))\n",
        "print('The critical error is : ',critical_error/len(all_real))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUfGuhkTY_le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Visualization of Confusion matrix\n",
        "#===============================================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_real, all_pred)\n",
        "plot_confusion_matrix(cm,\n",
        "                      ['neg','neu', 'pos'],\n",
        "                      title='Confusion matrix',\n",
        "                      cmap=None,\n",
        "                      normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZoI0HdcIMCu",
        "colab_type": "text"
      },
      "source": [
        "## Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe2uHGAYsyoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# import py for the EDA (Easy data Augmentation)\n",
        "# original code from https://github.com/jasonwei20/eda_nlp\n",
        "#===============================================================================\n",
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from easy_data_augmentation import *\n",
        "\n",
        "X, y1 = gen_eda(X, y1, alpha = 0.2, num_aug = 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iomsxilFIOnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd671f06-825b-4b99-c34e-f2f19d00fef5"
      },
      "source": [
        "#===============================================================================\n",
        "# Train for prediction\n",
        "#===============================================================================\n",
        "\n",
        "batch_size = 32\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "val_accuracy = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_inputs, train_masks = preprocessing_for_finbert(X)\n",
        "train_labels = torch.tensor(y1)\n",
        "#Data Loader Class\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=4, layers_to_freeze =  [0,1,2,3,4,5,6,7])\n",
        "train(bert_classifier, train_dataloader, epochs=4, evaluation=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.094467   |     -      |     -     |   22.50  \n",
            "   1    |   40    |   1.089724   |     -      |     -     |   21.29  \n",
            "   1    |   60    |   1.073637   |     -      |     -     |   21.09  \n",
            "   1    |   80    |   1.081177   |     -      |     -     |   21.07  \n",
            "   1    |   100   |   1.055020   |     -      |     -     |   20.99  \n",
            "   1    |   120   |   1.052293   |     -      |     -     |   21.01  \n",
            "   1    |   140   |   1.039601   |     -      |     -     |   21.03  \n",
            "   1    |   160   |   1.013533   |     -      |     -     |   20.99  \n",
            "   1    |   180   |   1.016024   |     -      |     -     |   20.98  \n",
            "   1    |   200   |   1.018843   |     -      |     -     |   20.99  \n",
            "   1    |   220   |   0.931638   |     -      |     -     |   20.90  \n",
            "   1    |   240   |   0.940779   |     -      |     -     |   20.89  \n",
            "   1    |   260   |   0.930990   |     -      |     -     |   20.88  \n",
            "   1    |   280   |   0.942459   |     -      |     -     |   20.89  \n",
            "   1    |   300   |   0.917108   |     -      |     -     |   20.90  \n",
            "   1    |   320   |   0.961865   |     -      |     -     |   20.93  \n",
            "   1    |   340   |   0.917752   |     -      |     -     |   20.89  \n",
            "   1    |   360   |   0.903314   |     -      |     -     |   20.92  \n",
            "   1    |   380   |   0.885496   |     -      |     -     |   20.92  \n",
            "   1    |   400   |   0.871716   |     -      |     -     |   20.92  \n",
            "   1    |   420   |   0.872129   |     -      |     -     |   20.95  \n",
            "   1    |   440   |   0.868863   |     -      |     -     |   20.90  \n",
            "   1    |   460   |   0.856888   |     -      |     -     |   20.89  \n",
            "   1    |   480   |   0.862244   |     -      |     -     |   20.92  \n",
            "   1    |   500   |   0.872804   |     -      |     -     |   20.92  \n",
            "   1    |   520   |   0.872066   |     -      |     -     |   20.93  \n",
            "   1    |   540   |   0.869123   |     -      |     -     |   20.93  \n",
            "   1    |   560   |   0.834444   |     -      |     -     |   20.93  \n",
            "   1    |   580   |   0.825976   |     -      |     -     |   20.88  \n",
            "   1    |   600   |   0.809005   |     -      |     -     |   20.91  \n",
            "   1    |   620   |   0.843282   |     -      |     -     |   20.92  \n",
            "   1    |   640   |   0.819220   |     -      |     -     |   20.91  \n",
            "   1    |   660   |   0.841547   |     -      |     -     |   20.90  \n",
            "   1    |   680   |   0.770048   |     -      |     -     |   20.93  \n",
            "   1    |   700   |   0.802873   |     -      |     -     |   20.91  \n",
            "   1    |   720   |   0.762965   |     -      |     -     |   20.90  \n",
            "   1    |   740   |   0.751210   |     -      |     -     |   20.93  \n",
            "   1    |   760   |   0.770565   |     -      |     -     |   20.90  \n",
            "   1    |   780   |   0.736036   |     -      |     -     |   20.92  \n",
            "   1    |   800   |   0.759620   |     -      |     -     |   20.91  \n",
            "   1    |   820   |   0.736997   |     -      |     -     |   20.92  \n",
            "   1    |   840   |   0.723072   |     -      |     -     |   20.93  \n",
            "   1    |   860   |   0.753355   |     -      |     -     |   20.93  \n",
            "   1    |   880   |   0.724206   |     -      |     -     |   20.91  \n",
            "   1    |   900   |   0.766465   |     -      |     -     |   20.94  \n",
            "   1    |   920   |   0.759618   |     -      |     -     |   20.92  \n",
            "   1    |   940   |   0.735336   |     -      |     -     |   20.92  \n",
            "   1    |   960   |   0.749675   |     -      |     -     |   20.92  \n",
            "   1    |   980   |   0.711887   |     -      |     -     |   20.94  \n",
            "   1    |  1000   |   0.658764   |     -      |     -     |   20.90  \n",
            "   1    |  1020   |   0.764668   |     -      |     -     |   20.92  \n",
            "   1    |  1040   |   0.673339   |     -      |     -     |   20.93  \n",
            "   1    |  1060   |   0.656780   |     -      |     -     |   20.92  \n",
            "   1    |  1080   |   0.736635   |     -      |     -     |   20.91  \n",
            "   1    |  1100   |   0.683257   |     -      |     -     |   20.91  \n",
            "   1    |  1120   |   0.641154   |     -      |     -     |   20.90  \n",
            "   1    |  1140   |   0.677583   |     -      |     -     |   20.96  \n",
            "   1    |  1160   |   0.612759   |     -      |     -     |   20.92  \n",
            "   1    |  1180   |   0.636844   |     -      |     -     |   20.96  \n",
            "   1    |  1200   |   0.690751   |     -      |     -     |   20.94  \n",
            "   1    |  1220   |   0.646951   |     -      |     -     |   20.93  \n",
            "   1    |  1240   |   0.600261   |     -      |     -     |   20.91  \n",
            "   1    |  1260   |   0.630362   |     -      |     -     |   20.94  \n",
            "   1    |  1280   |   0.651805   |     -      |     -     |   20.93  \n",
            "   1    |  1300   |   0.619401   |     -      |     -     |   20.96  \n",
            "   1    |  1320   |   0.628758   |     -      |     -     |   20.93  \n",
            "   1    |  1340   |   0.647059   |     -      |     -     |   20.94  \n",
            "   1    |  1360   |   0.590085   |     -      |     -     |   20.92  \n",
            "   1    |  1380   |   0.563988   |     -      |     -     |   20.93  \n",
            "   1    |  1400   |   0.590349   |     -      |     -     |   20.95  \n",
            "   1    |  1420   |   0.610342   |     -      |     -     |   20.90  \n",
            "   1    |  1439   |   0.591598   |     -      |     -     |   19.67  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.493434   |     -      |     -     |   21.97  \n",
            "   2    |   40    |   0.467775   |     -      |     -     |   20.95  \n",
            "   2    |   60    |   0.478361   |     -      |     -     |   20.91  \n",
            "   2    |   80    |   0.476333   |     -      |     -     |   20.93  \n",
            "   2    |   100   |   0.497058   |     -      |     -     |   20.94  \n",
            "   2    |   120   |   0.504305   |     -      |     -     |   20.93  \n",
            "   2    |   140   |   0.505306   |     -      |     -     |   20.93  \n",
            "   2    |   160   |   0.432410   |     -      |     -     |   20.95  \n",
            "   2    |   180   |   0.425390   |     -      |     -     |   20.91  \n",
            "   2    |   200   |   0.453481   |     -      |     -     |   20.93  \n",
            "   2    |   220   |   0.418112   |     -      |     -     |   20.89  \n",
            "   2    |   240   |   0.391332   |     -      |     -     |   20.92  \n",
            "   2    |   260   |   0.463173   |     -      |     -     |   20.91  \n",
            "   2    |   280   |   0.457208   |     -      |     -     |   20.92  \n",
            "   2    |   300   |   0.461218   |     -      |     -     |   20.90  \n",
            "   2    |   320   |   0.459181   |     -      |     -     |   20.93  \n",
            "   2    |   340   |   0.435953   |     -      |     -     |   20.93  \n",
            "   2    |   360   |   0.402812   |     -      |     -     |   20.92  \n",
            "   2    |   380   |   0.368533   |     -      |     -     |   20.96  \n",
            "   2    |   400   |   0.389803   |     -      |     -     |   20.93  \n",
            "   2    |   420   |   0.352480   |     -      |     -     |   20.92  \n",
            "   2    |   440   |   0.373103   |     -      |     -     |   20.93  \n",
            "   2    |   460   |   0.389266   |     -      |     -     |   20.93  \n",
            "   2    |   480   |   0.366837   |     -      |     -     |   20.93  \n",
            "   2    |   500   |   0.431705   |     -      |     -     |   20.93  \n",
            "   2    |   520   |   0.357314   |     -      |     -     |   20.95  \n",
            "   2    |   540   |   0.390939   |     -      |     -     |   20.91  \n",
            "   2    |   560   |   0.334365   |     -      |     -     |   20.93  \n",
            "   2    |   580   |   0.371078   |     -      |     -     |   20.94  \n",
            "   2    |   600   |   0.360924   |     -      |     -     |   20.91  \n",
            "   2    |   620   |   0.312077   |     -      |     -     |   20.93  \n",
            "   2    |   640   |   0.371932   |     -      |     -     |   20.93  \n",
            "   2    |   660   |   0.343281   |     -      |     -     |   20.93  \n",
            "   2    |   680   |   0.430520   |     -      |     -     |   20.93  \n",
            "   2    |   700   |   0.338793   |     -      |     -     |   20.89  \n",
            "   2    |   720   |   0.365755   |     -      |     -     |   20.91  \n",
            "   2    |   740   |   0.334916   |     -      |     -     |   20.93  \n",
            "   2    |   760   |   0.324000   |     -      |     -     |   20.90  \n",
            "   2    |   780   |   0.335680   |     -      |     -     |   20.91  \n",
            "   2    |   800   |   0.371874   |     -      |     -     |   20.91  \n",
            "   2    |   820   |   0.349244   |     -      |     -     |   20.93  \n",
            "   2    |   840   |   0.362601   |     -      |     -     |   20.93  \n",
            "   2    |   860   |   0.329104   |     -      |     -     |   20.92  \n",
            "   2    |   880   |   0.366702   |     -      |     -     |   20.95  \n",
            "   2    |   900   |   0.346194   |     -      |     -     |   20.92  \n",
            "   2    |   920   |   0.326370   |     -      |     -     |   20.92  \n",
            "   2    |   940   |   0.348968   |     -      |     -     |   20.93  \n",
            "   2    |   960   |   0.297984   |     -      |     -     |   20.93  \n",
            "   2    |   980   |   0.357625   |     -      |     -     |   20.94  \n",
            "   2    |  1000   |   0.337802   |     -      |     -     |   20.94  \n",
            "   2    |  1020   |   0.338282   |     -      |     -     |   20.94  \n",
            "   2    |  1040   |   0.343492   |     -      |     -     |   20.94  \n",
            "   2    |  1060   |   0.316092   |     -      |     -     |   20.91  \n",
            "   2    |  1080   |   0.323812   |     -      |     -     |   20.92  \n",
            "   2    |  1100   |   0.282943   |     -      |     -     |   20.93  \n",
            "   2    |  1120   |   0.295479   |     -      |     -     |   20.92  \n",
            "   2    |  1140   |   0.272915   |     -      |     -     |   20.91  \n",
            "   2    |  1160   |   0.313794   |     -      |     -     |   20.92  \n",
            "   2    |  1180   |   0.262388   |     -      |     -     |   20.89  \n",
            "   2    |  1200   |   0.291527   |     -      |     -     |   20.94  \n",
            "   2    |  1220   |   0.274985   |     -      |     -     |   20.92  \n",
            "   2    |  1240   |   0.272944   |     -      |     -     |   20.92  \n",
            "   2    |  1260   |   0.357194   |     -      |     -     |   20.91  \n",
            "   2    |  1280   |   0.327457   |     -      |     -     |   20.90  \n",
            "   2    |  1300   |   0.297045   |     -      |     -     |   20.93  \n",
            "   2    |  1320   |   0.243397   |     -      |     -     |   20.93  \n",
            "   2    |  1340   |   0.254440   |     -      |     -     |   20.92  \n",
            "   2    |  1360   |   0.293533   |     -      |     -     |   20.92  \n",
            "   2    |  1380   |   0.290704   |     -      |     -     |   20.92  \n",
            "   2    |  1400   |   0.243570   |     -      |     -     |   20.91  \n",
            "   2    |  1420   |   0.282516   |     -      |     -     |   20.95  \n",
            "   2    |  1439   |   0.262614   |     -      |     -     |   19.70  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.205058   |     -      |     -     |   21.93  \n",
            "   3    |   40    |   0.208289   |     -      |     -     |   20.91  \n",
            "   3    |   60    |   0.167803   |     -      |     -     |   20.91  \n",
            "   3    |   80    |   0.178889   |     -      |     -     |   20.91  \n",
            "   3    |   100   |   0.179262   |     -      |     -     |   20.97  \n",
            "   3    |   120   |   0.226278   |     -      |     -     |   20.90  \n",
            "   3    |   140   |   0.170487   |     -      |     -     |   20.91  \n",
            "   3    |   160   |   0.155282   |     -      |     -     |   20.95  \n",
            "   3    |   180   |   0.186457   |     -      |     -     |   20.92  \n",
            "   3    |   200   |   0.147444   |     -      |     -     |   20.89  \n",
            "   3    |   220   |   0.162464   |     -      |     -     |   20.93  \n",
            "   3    |   240   |   0.151478   |     -      |     -     |   20.94  \n",
            "   3    |   260   |   0.169418   |     -      |     -     |   20.92  \n",
            "   3    |   280   |   0.143483   |     -      |     -     |   20.95  \n",
            "   3    |   300   |   0.185069   |     -      |     -     |   20.91  \n",
            "   3    |   320   |   0.142869   |     -      |     -     |   20.93  \n",
            "   3    |   340   |   0.166668   |     -      |     -     |   20.90  \n",
            "   3    |   360   |   0.188006   |     -      |     -     |   20.93  \n",
            "   3    |   380   |   0.155562   |     -      |     -     |   20.93  \n",
            "   3    |   400   |   0.173279   |     -      |     -     |   20.93  \n",
            "   3    |   420   |   0.186558   |     -      |     -     |   20.90  \n",
            "   3    |   440   |   0.145299   |     -      |     -     |   20.93  \n",
            "   3    |   460   |   0.217888   |     -      |     -     |   20.91  \n",
            "   3    |   480   |   0.146963   |     -      |     -     |   20.90  \n",
            "   3    |   500   |   0.145566   |     -      |     -     |   20.92  \n",
            "   3    |   520   |   0.168084   |     -      |     -     |   20.92  \n",
            "   3    |   540   |   0.194412   |     -      |     -     |   20.93  \n",
            "   3    |   560   |   0.160022   |     -      |     -     |   20.92  \n",
            "   3    |   580   |   0.160969   |     -      |     -     |   20.91  \n",
            "   3    |   600   |   0.173149   |     -      |     -     |   20.89  \n",
            "   3    |   620   |   0.184733   |     -      |     -     |   20.94  \n",
            "   3    |   640   |   0.163177   |     -      |     -     |   20.93  \n",
            "   3    |   660   |   0.109585   |     -      |     -     |   20.91  \n",
            "   3    |   680   |   0.160280   |     -      |     -     |   20.91  \n",
            "   3    |   700   |   0.128184   |     -      |     -     |   20.91  \n",
            "   3    |   720   |   0.144048   |     -      |     -     |   20.92  \n",
            "   3    |   740   |   0.162427   |     -      |     -     |   20.95  \n",
            "   3    |   760   |   0.171321   |     -      |     -     |   20.95  \n",
            "   3    |   780   |   0.134295   |     -      |     -     |   20.92  \n",
            "   3    |   800   |   0.176006   |     -      |     -     |   20.93  \n",
            "   3    |   820   |   0.170686   |     -      |     -     |   20.92  \n",
            "   3    |   840   |   0.138944   |     -      |     -     |   20.94  \n",
            "   3    |   860   |   0.174612   |     -      |     -     |   20.93  \n",
            "   3    |   880   |   0.108606   |     -      |     -     |   20.89  \n",
            "   3    |   900   |   0.159704   |     -      |     -     |   20.91  \n",
            "   3    |   920   |   0.139188   |     -      |     -     |   20.93  \n",
            "   3    |   940   |   0.149009   |     -      |     -     |   20.91  \n",
            "   3    |   960   |   0.181259   |     -      |     -     |   20.89  \n",
            "   3    |   980   |   0.135600   |     -      |     -     |   20.90  \n",
            "   3    |  1000   |   0.173865   |     -      |     -     |   20.91  \n",
            "   3    |  1020   |   0.094122   |     -      |     -     |   20.92  \n",
            "   3    |  1040   |   0.153749   |     -      |     -     |   20.93  \n",
            "   3    |  1060   |   0.129340   |     -      |     -     |   20.91  \n",
            "   3    |  1080   |   0.133265   |     -      |     -     |   20.92  \n",
            "   3    |  1100   |   0.128098   |     -      |     -     |   20.94  \n",
            "   3    |  1120   |   0.127286   |     -      |     -     |   20.95  \n",
            "   3    |  1140   |   0.143569   |     -      |     -     |   20.90  \n",
            "   3    |  1160   |   0.135599   |     -      |     -     |   20.94  \n",
            "   3    |  1180   |   0.118498   |     -      |     -     |   20.90  \n",
            "   3    |  1200   |   0.140193   |     -      |     -     |   20.93  \n",
            "   3    |  1220   |   0.125386   |     -      |     -     |   20.91  \n",
            "   3    |  1240   |   0.135726   |     -      |     -     |   20.95  \n",
            "   3    |  1260   |   0.162849   |     -      |     -     |   20.93  \n",
            "   3    |  1280   |   0.152644   |     -      |     -     |   20.95  \n",
            "   3    |  1300   |   0.156196   |     -      |     -     |   20.96  \n",
            "   3    |  1320   |   0.117959   |     -      |     -     |   20.92  \n",
            "   3    |  1340   |   0.120557   |     -      |     -     |   20.94  \n",
            "   3    |  1360   |   0.099253   |     -      |     -     |   20.93  \n",
            "   3    |  1380   |   0.116627   |     -      |     -     |   20.91  \n",
            "   3    |  1400   |   0.121895   |     -      |     -     |   20.90  \n",
            "   3    |  1420   |   0.128546   |     -      |     -     |   20.91  \n",
            "   3    |  1439   |   0.091278   |     -      |     -     |   19.65  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.100206   |     -      |     -     |   21.95  \n",
            "   4    |   40    |   0.077999   |     -      |     -     |   20.93  \n",
            "   4    |   60    |   0.077434   |     -      |     -     |   20.89  \n",
            "   4    |   80    |   0.058294   |     -      |     -     |   20.94  \n",
            "   4    |   100   |   0.081061   |     -      |     -     |   20.90  \n",
            "   4    |   120   |   0.076914   |     -      |     -     |   20.92  \n",
            "   4    |   140   |   0.078675   |     -      |     -     |   20.93  \n",
            "   4    |   160   |   0.065793   |     -      |     -     |   20.88  \n",
            "   4    |   180   |   0.063620   |     -      |     -     |   20.90  \n",
            "   4    |   200   |   0.113569   |     -      |     -     |   20.89  \n",
            "   4    |   220   |   0.065519   |     -      |     -     |   20.90  \n",
            "   4    |   240   |   0.090113   |     -      |     -     |   20.89  \n",
            "   4    |   260   |   0.087935   |     -      |     -     |   20.89  \n",
            "   4    |   280   |   0.118856   |     -      |     -     |   20.93  \n",
            "   4    |   300   |   0.092019   |     -      |     -     |   20.88  \n",
            "   4    |   320   |   0.058358   |     -      |     -     |   20.91  \n",
            "   4    |   340   |   0.070424   |     -      |     -     |   20.93  \n",
            "   4    |   360   |   0.076389   |     -      |     -     |   20.89  \n",
            "   4    |   380   |   0.072749   |     -      |     -     |   20.90  \n",
            "   4    |   400   |   0.077612   |     -      |     -     |   20.91  \n",
            "   4    |   420   |   0.106705   |     -      |     -     |   20.90  \n",
            "   4    |   440   |   0.069170   |     -      |     -     |   20.92  \n",
            "   4    |   460   |   0.032923   |     -      |     -     |   20.86  \n",
            "   4    |   480   |   0.086733   |     -      |     -     |   20.86  \n",
            "   4    |   500   |   0.097199   |     -      |     -     |   20.93  \n",
            "   4    |   520   |   0.115318   |     -      |     -     |   20.92  \n",
            "   4    |   540   |   0.111822   |     -      |     -     |   20.90  \n",
            "   4    |   560   |   0.071797   |     -      |     -     |   20.91  \n",
            "   4    |   580   |   0.071954   |     -      |     -     |   20.90  \n",
            "   4    |   600   |   0.090345   |     -      |     -     |   20.90  \n",
            "   4    |   620   |   0.105174   |     -      |     -     |   20.95  \n",
            "   4    |   640   |   0.077558   |     -      |     -     |   20.91  \n",
            "   4    |   660   |   0.068182   |     -      |     -     |   20.92  \n",
            "   4    |   680   |   0.072355   |     -      |     -     |   20.91  \n",
            "   4    |   700   |   0.073752   |     -      |     -     |   20.89  \n",
            "   4    |   720   |   0.079040   |     -      |     -     |   20.90  \n",
            "   4    |   740   |   0.069587   |     -      |     -     |   20.90  \n",
            "   4    |   760   |   0.087328   |     -      |     -     |   20.88  \n",
            "   4    |   780   |   0.065756   |     -      |     -     |   20.90  \n",
            "   4    |   800   |   0.059806   |     -      |     -     |   20.92  \n",
            "   4    |   820   |   0.081425   |     -      |     -     |   20.91  \n",
            "   4    |   840   |   0.065802   |     -      |     -     |   20.89  \n",
            "   4    |   860   |   0.140394   |     -      |     -     |   20.91  \n",
            "   4    |   880   |   0.042623   |     -      |     -     |   20.91  \n",
            "   4    |   900   |   0.059784   |     -      |     -     |   20.94  \n",
            "   4    |   920   |   0.098158   |     -      |     -     |   20.93  \n",
            "   4    |   940   |   0.072094   |     -      |     -     |   20.92  \n",
            "   4    |   960   |   0.072314   |     -      |     -     |   20.90  \n",
            "   4    |   980   |   0.073069   |     -      |     -     |   20.91  \n",
            "   4    |  1000   |   0.081823   |     -      |     -     |   20.90  \n",
            "   4    |  1020   |   0.081107   |     -      |     -     |   20.90  \n",
            "   4    |  1040   |   0.062792   |     -      |     -     |   20.87  \n",
            "   4    |  1060   |   0.084077   |     -      |     -     |   20.91  \n",
            "   4    |  1080   |   0.058294   |     -      |     -     |   20.89  \n",
            "   4    |  1100   |   0.068403   |     -      |     -     |   20.92  \n",
            "   4    |  1120   |   0.053853   |     -      |     -     |   20.91  \n",
            "   4    |  1140   |   0.087993   |     -      |     -     |   20.92  \n",
            "   4    |  1160   |   0.054785   |     -      |     -     |   20.91  \n",
            "   4    |  1180   |   0.077010   |     -      |     -     |   20.92  \n",
            "   4    |  1200   |   0.075166   |     -      |     -     |   20.90  \n",
            "   4    |  1220   |   0.067512   |     -      |     -     |   20.92  \n",
            "   4    |  1240   |   0.085395   |     -      |     -     |   20.88  \n",
            "   4    |  1260   |   0.050669   |     -      |     -     |   20.87  \n",
            "   4    |  1280   |   0.041852   |     -      |     -     |   20.90  \n",
            "   4    |  1300   |   0.076112   |     -      |     -     |   20.93  \n",
            "   4    |  1320   |   0.049631   |     -      |     -     |   20.87  \n",
            "   4    |  1340   |   0.059712   |     -      |     -     |   20.88  \n",
            "   4    |  1360   |   0.059213   |     -      |     -     |   20.91  \n",
            "   4    |  1380   |   0.084955   |     -      |     -     |   20.91  \n",
            "   4    |  1400   |   0.074622   |     -      |     -     |   20.94  \n",
            "   4    |  1420   |   0.100819   |     -      |     -     |   20.92  \n",
            "   4    |  1439   |   0.054621   |     -      |     -     |   19.66  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVVtqHZcKQYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Prediction function \n",
        "#===============================================================================\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    val_accuracy = []\n",
        "    all_pred = []\n",
        "    all_real = []\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "        all_real.append(b_labels)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        all_pred.append(preds)\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    all_real = torch.cat(all_real)\n",
        "    all_pred = torch.cat(all_pred)\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    #val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_accuracy,all_real, all_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnbOS4kdIP_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "04f55274-ffb1-4cbf-968b-ff624aa0ae49"
      },
      "source": [
        "#===============================================================================\n",
        "# Test the trained model\n",
        "#===============================================================================\n",
        "df_test = pd.read_json('/content/drive/My Drive/KIS data/test_data.json')\n",
        "\n",
        "print(len(df_test))\n",
        "idx_to_remove = []\n",
        "for i in range(len(df_test)):\n",
        "  if type(df_test['summary'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "  if type(df_test['title'][i]) == float:\n",
        "    idx_to_remove.append(i)\n",
        "\n",
        "df_test = df_test.iloc[list(set(df_test.index) - set(idx_to_remove))]\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_test['title_summary'] = df_test['title'] + ' ' + df_test['summary']\n",
        "df_test= df_test.drop(df_test[df_test['title_summary'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "df_test= df_test.drop(df_test[df_test['importance'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "df_test= df_test.drop(df_test[df_test['sentiment'].isnull()].index)\n",
        "df_test.index = np.arange(0, len(df_test))\n",
        "title_summary_len = [len(df_test['title_summary'][i].split(' ')) for i in range(len(df_test))]\n",
        "df_stat = pd.DataFrame(title_summary_len)\n",
        "df_stat.describe()\n",
        "print(len(df_test))\n",
        "\n",
        "X_test, y1_test, y2_test = df_test['title_summary'], df_test['sentiment'].apply(int), df_test['importance'].apply(int)\n",
        "y1_test_values, y2_test_values = y1_test.values, y2_test.values\n",
        "\n",
        "label_count_test_1, label_count_test_2 = [0,0,0], [0,0,0]\n",
        "for i in range(len(y1_test)):\n",
        "  label_count_test_1[y1_test_values[i]] += 1\n",
        "  label_count_test_2[y2_test_values[i]] += 1\n",
        "\n",
        "print(label_count_test_1, label_count_test_2)\n",
        "print([round(label_count_test_1[i]/sum(label_count_test_1),3) for i in range(len(label_count_test_1))], [round(label_count_test_2[i]/sum(label_count_test_2),3) for i in range(len(label_count_test_2))])\n",
        "\n",
        "test_inputs, test_masks = preprocessing_for_finbert(X_test)\n",
        "test_labels = torch.tensor(y1_test)\n",
        "#Data Loader Class\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)\n",
        "\n",
        "acc,all_real, all_pred = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "critical_error = 0\n",
        "crit_error_index = []\n",
        "hit = 0\n",
        "for i in range(len(all_real)):\n",
        "  if all_real[i] == all_pred[i]:\n",
        "    hit += 1\n",
        "  if abs(all_pred[i] - all_real[i]) == 2:\n",
        "    critical_error += 1\n",
        "    crit_error_index.append(i)\n",
        "\n",
        "all_pred = all_pred.cpu().numpy()\n",
        "all_real = all_real.cpu().numpy()\n",
        "\n",
        "print('The accuracy of the model is :', hit/len(all_real))\n",
        "print('The critical error is : ',critical_error/len(all_real))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2898\n",
            "2866\n",
            "[366, 1585, 915] [1052, 918, 896]\n",
            "[0.128, 0.553, 0.319] [0.367, 0.32, 0.313]\n",
            "The accuracy of the model is : 0.4110258199581298\n",
            "The critical error is :  0.12247034193998604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vcwe2oaISO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "py_file_location ='/content/drive/My Drive/Lib'\n",
        "sys.path.append(py_file_location)\n",
        "\n",
        "from confusion_matrix import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P1MPiPdIRk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "74e2d32f-0cf0-409a-9b36-5f6a79fe892b"
      },
      "source": [
        "#===============================================================================\n",
        "# Visualization of confusion matrix\n",
        "#===============================================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(all_real, all_pred)\n",
        "plot_confusion_matrix(cm,\n",
        "                      ['neg','neu', 'pos'],\n",
        "                      title='Confusion matrix',\n",
        "                      cmap=None,\n",
        "                      normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}